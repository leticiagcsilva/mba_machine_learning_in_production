{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DICIONARIO DE DADOS**\n",
    "- **id**: ID de assinante exclusivo.\n",
    "- **is_tv_subscriber**: se o cliente tem assinatura de TV.\n",
    "- **is_movie_package_subscriber**: se o cliente tem um pacote de filmes de cinema.\n",
    "- **subscription_age**: há quantos anos o cliente usa o serviço.\n",
    "- **bill_avg**: média da fatura dos últimos 3 meses.\n",
    "- **reamining_contract**: quantos anos restantes para o contrato do cliente. Se **nulo**, o cliente não tem contrato.\n",
    "- **service_failure_count**: contagem de chamadas de clientes para call center por falha de serviço nos últimos 3 meses.\n",
    "- **download_avg**: últimos 3 meses de uso de internet (GB).\n",
    "- **upload_avg**: média de upload dos últimos três meses (GB).\n",
    "- **download_over_limit**: a maioria dos clientes tem um limite de download. se atingirem esse limite, terão que pagar por isso. Esta coluna contém quantidade acima do limite.\n",
    "- **churn**: se o cliente deu churn ou não"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Download Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\letic\\anaconda\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\letic\\anaconda\\lib\\site-packages (from optuna) (1.12.0)\n",
      "Requirement already satisfied: cmaes>=0.10.0 in c:\\users\\letic\\anaconda\\lib\\site-packages (from optuna) (0.10.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\letic\\anaconda\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\letic\\anaconda\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\letic\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\letic\\anaconda\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\letic\\anaconda\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\letic\\anaconda\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\letic\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\letic\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\letic\\anaconda\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\letic\\appdata\\roaming\\python\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\letic\\anaconda\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\letic\\anaconda\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\letic\\anaconda\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\letic\\anaconda\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\letic\\anaconda\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\letic\\anaconda\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\letic\\anaconda\\lib\\site-packages (from lightgbm) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Upload Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72274 entries, 0 to 72273\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   id                           72274 non-null  int64  \n",
      " 1   is_tv_subscriber             72274 non-null  int64  \n",
      " 2   is_movie_package_subscriber  72274 non-null  int64  \n",
      " 3   subscription_age             72274 non-null  float64\n",
      " 4   bill_avg                     72274 non-null  int64  \n",
      " 5   reamining_contract           50702 non-null  float64\n",
      " 6   service_failure_count        72274 non-null  int64  \n",
      " 7   download_avg                 71893 non-null  float64\n",
      " 8   upload_avg                   71893 non-null  float64\n",
      " 9   download_over_limit          72274 non-null  int64  \n",
      " 10  churn                        72274 non-null  int64  \n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 6.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_tv_subscriber</th>\n",
       "      <th>is_movie_package_subscriber</th>\n",
       "      <th>subscription_age</th>\n",
       "      <th>bill_avg</th>\n",
       "      <th>reamining_contract</th>\n",
       "      <th>service_failure_count</th>\n",
       "      <th>download_avg</th>\n",
       "      <th>upload_avg</th>\n",
       "      <th>download_over_limit</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.95</td>\n",
       "      <td>25</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_tv_subscriber  is_movie_package_subscriber  subscription_age  \\\n",
       "0  15                 1                            0             11.95   \n",
       "1  18                 0                            0              8.22   \n",
       "\n",
       "   bill_avg  reamining_contract  service_failure_count  download_avg  \\\n",
       "0        25                0.14                      0           8.4   \n",
       "1         0                 NaN                      0           0.0   \n",
       "\n",
       "   upload_avg  download_over_limit  churn  \n",
       "0         2.3                    0      0  \n",
       "1         0.0                    0      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/atividade-2-churn-internet.csv')\n",
    "display(df.info())\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_tv_subscriber</th>\n",
       "      <th>is_movie_package_subscriber</th>\n",
       "      <th>subscription_age</th>\n",
       "      <th>bill_avg</th>\n",
       "      <th>reamining_contract</th>\n",
       "      <th>service_failure_count</th>\n",
       "      <th>download_avg</th>\n",
       "      <th>upload_avg</th>\n",
       "      <th>download_over_limit</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.95</td>\n",
       "      <td>25</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_tv_subscriber  is_movie_package_subscriber  subscription_age  \\\n",
       "0  15                 1                            0             11.95   \n",
       "1  18                 0                            0              8.22   \n",
       "\n",
       "   bill_avg  reamining_contract  service_failure_count  download_avg  \\\n",
       "0        25                0.14                      0           8.4   \n",
       "1         0                 NaN                      0           0.0   \n",
       "\n",
       "   upload_avg  download_over_limit  churn  \n",
       "0         2.3                    0      0  \n",
       "1         0.0                    0      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0.000000\n",
       "is_tv_subscriber               0.000000\n",
       "is_movie_package_subscriber    0.000000\n",
       "subscription_age               0.000000\n",
       "bill_avg                       0.000000\n",
       "reamining_contract             0.298475\n",
       "service_failure_count          0.000000\n",
       "download_avg                   0.005272\n",
       "upload_avg                     0.005272\n",
       "download_over_limit            0.000000\n",
       "churn                          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os valores faltantes de **download_avg** e **upload_avg**, são abaixo de 5%, vamos excluí-los do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['download_avg', 'upload_avg'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['churn', 'id'], axis=1)\n",
    "y = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_tv_subscriber</th>\n",
       "      <th>is_movie_package_subscriber</th>\n",
       "      <th>subscription_age</th>\n",
       "      <th>bill_avg</th>\n",
       "      <th>reamining_contract</th>\n",
       "      <th>service_failure_count</th>\n",
       "      <th>download_avg</th>\n",
       "      <th>upload_avg</th>\n",
       "      <th>download_over_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.95</td>\n",
       "      <td>25</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.87</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_tv_subscriber  is_movie_package_subscriber  subscription_age  bill_avg  \\\n",
       "0                 1                            0             11.95        25   \n",
       "1                 0                            0              8.22         0   \n",
       "2                 1                            0              8.91        16   \n",
       "3                 0                            0              6.87        21   \n",
       "4                 0                            0              6.39         0   \n",
       "\n",
       "   reamining_contract  service_failure_count  download_avg  upload_avg  \\\n",
       "0                0.14                      0           8.4         2.3   \n",
       "1                 NaN                      0           0.0         0.0   \n",
       "2                0.00                      0          13.7         0.9   \n",
       "3                 NaN                      1           0.0         0.0   \n",
       "4                 NaN                      0           0.0         0.0   \n",
       "\n",
       "   download_over_limit  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50325, 9)\n",
      "X_test: (21568, 9)\n"
     ]
    }
   ],
   "source": [
    "#Como não temos desbalanceamento na nossa variável alvo, não precisaremos fazer uso do argumento stratify da função train_test_split() disponível na biblioteca Scikit-learn.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "                                                    \n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 0.7\n",
      "y_train: 0.7\n",
      "X_test: 0.3\n",
      "y_test: 0.3\n"
     ]
    }
   ],
   "source": [
    "print('X_train: {:.1f}'.format(len(X_train)/len(df)))\n",
    "print('y_train: {:.1f}'.format(len(y_train)/len(df)))\n",
    "print('X_test: {:.1f}'.format(len(X_test)/len(df)))\n",
    "print('y_test: {:.1f}'.format(len(y_test)/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_tv_subscriber               0.000000\n",
       "is_movie_package_subscriber    0.000000\n",
       "subscription_age               0.000000\n",
       "bill_avg                       0.000000\n",
       "reamining_contract             0.297089\n",
       "service_failure_count          0.000000\n",
       "download_avg                   0.000000\n",
       "upload_avg                     0.000000\n",
       "download_over_limit            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_tv_subscriber               0.000000\n",
       "is_movie_package_subscriber    0.000000\n",
       "subscription_age               0.000000\n",
       "bill_avg                       0.000000\n",
       "reamining_contract             0.304479\n",
       "service_failure_count          0.000000\n",
       "download_avg                   0.000000\n",
       "upload_avg                     0.000000\n",
       "download_over_limit            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valore nulos de **download_avg** e **upload_avg** serão excluídos, já os valores faltantes de **reamining_contract** necessitarão de um tratamento melhor, vamos criar uma nova coluna cahamada **reamining_contract_cat**, nela teremos os valores distribuídos em 4 categorias (os quantis) e os que não possuem contrato, serão classificados e uma nova categoria  **no_contract**.                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_remaining_contract(data):\n",
    "    data['reamining_contract_cat'] = pd.cut(data['reamining_contract'], \n",
    "                                           bins=[-float('inf'), data['reamining_contract'].quantile(0.25),\n",
    "                                                 data['reamining_contract'].quantile(0.5),\n",
    "                                                 data['reamining_contract'].quantile(0.75), float('inf')],\n",
    "                                           labels=['Q1', 'Q2', 'Q3', 'Q4'], include_lowest=True)\n",
    "    \n",
    "    data['reamining_contract_cat'] = data['reamining_contract_cat'].cat.add_categories('no_contract')\n",
    "    data['reamining_contract_cat'].fillna('no_contract', inplace=True)\n",
    "    data.drop('reamining_contract', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def process_remaining_contract(data):\n",
    "#     data['reamining_contract_cat'] = pd.cut(data['reamining_contract'], \n",
    "#                                            bins=[-float('inf'), data['reamining_contract'].quantile(0.25),\n",
    "#                                                  data['reamining_contract'].quantile(0.5),\n",
    "#                                                  data['reamining_contract'].quantile(0.75), float('inf')],\n",
    "#                                            labels=['Q1', 'Q2', 'Q3', 'Q4'], include_lowest=True)\n",
    "#     data['reamining_contract_cat'] = data['reamining_contract_cat'].cat.add_categories('no_contract')\n",
    "#     data['reamining_contract_cat'].fillna('no_contract', inplace=True)\n",
    "#     data.drop('reamining_contract', axis=1, inplace=True)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_tv_subscriber</th>\n",
       "      <th>is_movie_package_subscriber</th>\n",
       "      <th>subscription_age</th>\n",
       "      <th>bill_avg</th>\n",
       "      <th>service_failure_count</th>\n",
       "      <th>download_avg</th>\n",
       "      <th>upload_avg</th>\n",
       "      <th>download_over_limit</th>\n",
       "      <th>reamining_contract_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.59</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61539</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21901</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45193</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>57.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_tv_subscriber  is_movie_package_subscriber  subscription_age  \\\n",
       "3088                  1                            0              5.84   \n",
       "46248                 1                            1              2.59   \n",
       "61539                 1                            0              0.93   \n",
       "21901                 1                            0              0.10   \n",
       "45193                 1                            0              1.97   \n",
       "\n",
       "       bill_avg  service_failure_count  download_avg  upload_avg  \\\n",
       "3088         10                      1           0.0         0.0   \n",
       "46248        15                      0         209.7        15.9   \n",
       "61539        13                      0          22.2         1.2   \n",
       "21901         9                      0           0.0         0.0   \n",
       "45193        21                      2          57.6         6.3   \n",
       "\n",
       "       download_over_limit reamining_contract_cat  \n",
       "3088                     0            no_contract  \n",
       "46248                    0                     Q4  \n",
       "61539                    0                     Q3  \n",
       "21901                    0                     Q2  \n",
       "45193                    0                     Q1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = process_remaining_contract(X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_tv_subscriber</th>\n",
       "      <th>is_movie_package_subscriber</th>\n",
       "      <th>subscription_age</th>\n",
       "      <th>bill_avg</th>\n",
       "      <th>service_failure_count</th>\n",
       "      <th>download_avg</th>\n",
       "      <th>upload_avg</th>\n",
       "      <th>download_over_limit</th>\n",
       "      <th>reamining_contract_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>no_contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61853</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35774</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>120.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_tv_subscriber  is_movie_package_subscriber  subscription_age  \\\n",
       "50375                 1                            1              2.08   \n",
       "32250                 0                            0              4.38   \n",
       "35894                 0                            0              0.21   \n",
       "61853                 1                            0              0.25   \n",
       "35774                 1                            1              4.11   \n",
       "\n",
       "       bill_avg  service_failure_count  download_avg  upload_avg  \\\n",
       "50375        18                      0         106.3        14.2   \n",
       "32250        19                      0          23.8         7.6   \n",
       "35894        14                      0           5.0         0.3   \n",
       "61853        12                      0          31.0         4.9   \n",
       "35774        18                      2         120.9         5.4   \n",
       "\n",
       "       download_over_limit reamining_contract_cat  \n",
       "50375                    0                     Q4  \n",
       "32250                    0                     Q4  \n",
       "35894                    0            no_contract  \n",
       "61853                    0                     Q1  \n",
       "35774                    0                     Q4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = process_remaining_contract(X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_tv_subscriber               0.0\n",
       "is_movie_package_subscriber    0.0\n",
       "subscription_age               0.0\n",
       "bill_avg                       0.0\n",
       "service_failure_count          0.0\n",
       "download_avg                   0.0\n",
       "upload_avg                     0.0\n",
       "download_over_limit            0.0\n",
       "reamining_contract_cat         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_tv_subscriber               0.0\n",
       "is_movie_package_subscriber    0.0\n",
       "subscription_age               0.0\n",
       "bill_avg                       0.0\n",
       "service_failure_count          0.0\n",
       "download_avg                   0.0\n",
       "upload_avg                     0.0\n",
       "download_over_limit            0.0\n",
       "reamining_contract_cat         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_cols = ['subscription_age', 'bill_avg', 'service_failure_count', 'download_avg', 'upload_avg']\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['is_tv_subscriber', 'is_movie_package_subscriber', 'download_over_limit', 'reamining_contract_cat']\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        ('num', numeric_transformer, numeric_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_lg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('lg', LogisticRegression(solver='liblinear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'lg__C': trial.suggest_float('lg__C', 1e-3, 1e2),\n",
    "        'lg__penalty': trial.suggest_categorical('lg__penalty', ['l2', 'l1']),\n",
    "       #'lg_class_weight': triel.suggest_float('lg_class_weight', )\n",
    "    }\n",
    "    pipeline_lg.set_params(**params)\n",
    "    cv_scores = cross_val_score(pipeline_lg, X_train, y_train, cv=5)\n",
    "    return cv_scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 10:43:25,559] A new study created in memory with name: no-name-6d5ee2fe-f528-4bc7-9ebe-259649134886\n",
      "[I 2023-09-04 10:43:26,377] Trial 0 finished with value: 0.922762046696473 and parameters: {'lg__C': 56.27205918298689, 'lg__penalty': 'l1'}. Best is trial 0 with value: 0.922762046696473.\n",
      "[I 2023-09-04 10:43:28,426] Trial 1 finished with value: 0.922762046696473 and parameters: {'lg__C': 63.63356981104344, 'lg__penalty': 'l2'}. Best is trial 0 with value: 0.922762046696473.\n",
      "[I 2023-09-04 10:43:29,294] Trial 2 finished with value: 0.922762046696473 and parameters: {'lg__C': 66.5196299595858, 'lg__penalty': 'l1'}. Best is trial 0 with value: 0.922762046696473.\n",
      "[I 2023-09-04 10:43:30,170] Trial 3 finished with value: 0.922762046696473 and parameters: {'lg__C': 94.3752196810988, 'lg__penalty': 'l1'}. Best is trial 0 with value: 0.922762046696473.\n",
      "[I 2023-09-04 10:43:31,057] Trial 4 finished with value: 0.92274217585693 and parameters: {'lg__C': 72.46063639267105, 'lg__penalty': 'l1'}. Best is trial 4 with value: 0.92274217585693.\n",
      "[I 2023-09-04 10:43:31,981] Trial 5 finished with value: 0.922762046696473 and parameters: {'lg__C': 90.20462417907133, 'lg__penalty': 'l1'}. Best is trial 4 with value: 0.92274217585693.\n",
      "[I 2023-09-04 10:43:50,791] Trial 6 finished with value: 0.9226825633383011 and parameters: {'lg__C': 3.135396199335815, 'lg__penalty': 'l1'}. Best is trial 6 with value: 0.9226825633383011.\n",
      "[I 2023-09-04 10:43:51,746] Trial 7 finished with value: 0.922762046696473 and parameters: {'lg__C': 82.93122732148375, 'lg__penalty': 'l1'}. Best is trial 6 with value: 0.9226825633383011.\n",
      "[I 2023-09-04 10:43:52,719] Trial 8 finished with value: 0.92274217585693 and parameters: {'lg__C': 50.018305507721664, 'lg__penalty': 'l1'}. Best is trial 6 with value: 0.9226825633383011.\n",
      "[I 2023-09-04 10:43:55,157] Trial 9 finished with value: 0.922762046696473 and parameters: {'lg__C': 77.66989732533868, 'lg__penalty': 'l2'}. Best is trial 6 with value: 0.9226825633383011.\n",
      "[I 2023-09-04 10:43:57,342] Trial 10 finished with value: 0.9226626924987581 and parameters: {'lg__C': 0.286794620978128, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:43:59,392] Trial 11 finished with value: 0.92274217585693 and parameters: {'lg__C': 5.577444496395697, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:01,276] Trial 12 finished with value: 0.9227223050173871 and parameters: {'lg__C': 2.816704039551826, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:03,358] Trial 13 finished with value: 0.92274217585693 and parameters: {'lg__C': 20.595336271156896, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:05,501] Trial 14 finished with value: 0.922762046696473 and parameters: {'lg__C': 30.03730485870884, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:07,497] Trial 15 finished with value: 0.922762046696473 and parameters: {'lg__C': 32.332684098932766, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:09,778] Trial 16 finished with value: 0.92274217585693 and parameters: {'lg__C': 12.304401747647399, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:26,729] Trial 17 finished with value: 0.9226626924987581 and parameters: {'lg__C': 2.411840461384088, 'lg__penalty': 'l1'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:29,173] Trial 18 finished with value: 0.92274217585693 and parameters: {'lg__C': 15.757851734368472, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:30,094] Trial 19 finished with value: 0.92274217585693 and parameters: {'lg__C': 33.2646934167757, 'lg__penalty': 'l1'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:32,279] Trial 20 finished with value: 0.922762046696473 and parameters: {'lg__C': 41.6024660589035, 'lg__penalty': 'l2'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:44:45,781] Trial 21 finished with value: 0.9226626924987581 and parameters: {'lg__C': 0.38550807597692166, 'lg__penalty': 'l1'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:45:04,636] Trial 22 finished with value: 0.922702434177844 and parameters: {'lg__C': 1.9233840472663781, 'lg__penalty': 'l1'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:45:05,507] Trial 23 finished with value: 0.92274217585693 and parameters: {'lg__C': 11.279141675118389, 'lg__penalty': 'l1'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:45:06,386] Trial 24 finished with value: 0.92274217585693 and parameters: {'lg__C': 20.56711529193297, 'lg__penalty': 'l1'}. Best is trial 10 with value: 0.9226626924987581.\n",
      "[I 2023-09-04 10:45:16,492] Trial 25 finished with value: 0.9225832091405863 and parameters: {'lg__C': 0.2786752763765953, 'lg__penalty': 'l1'}. Best is trial 25 with value: 0.9225832091405863.\n",
      "[I 2023-09-04 10:45:17,449] Trial 26 finished with value: 0.9227223050173871 and parameters: {'lg__C': 10.194176511025367, 'lg__penalty': 'l1'}. Best is trial 25 with value: 0.9225832091405863.\n",
      "[I 2023-09-04 10:45:18,385] Trial 27 finished with value: 0.92274217585693 and parameters: {'lg__C': 20.981127034692083, 'lg__penalty': 'l1'}. Best is trial 25 with value: 0.9225832091405863.\n",
      "[I 2023-09-04 10:45:20,363] Trial 28 finished with value: 0.92274217585693 and parameters: {'lg__C': 7.873725185353347, 'lg__penalty': 'l2'}. Best is trial 25 with value: 0.9225832091405863.\n",
      "[I 2023-09-04 10:45:21,270] Trial 29 finished with value: 0.92274217585693 and parameters: {'lg__C': 16.22006440285014, 'lg__penalty': 'l1'}. Best is trial 25 with value: 0.9225832091405863.\n",
      "[I 2023-09-04 10:45:36,760] Trial 30 finished with value: 0.922702434177844 and parameters: {'lg__C': 1.0122256376110967, 'lg__penalty': 'l1'}. Best is trial 25 with value: 0.9225832091405863.\n",
      "[I 2023-09-04 10:45:39,455] Trial 31 finished with value: 0.9227223050173871 and parameters: {'lg__C': 8.859613046522757, 'lg__penalty': 'l1'}. Best is trial 25 with value: 0.9225832091405863.\n",
      "[I 2023-09-04 10:45:48,080] Trial 32 finished with value: 0.9225832091405861 and parameters: {'lg__C': 0.20908859223763115, 'lg__penalty': 'l1'}. Best is trial 32 with value: 0.9225832091405861.\n",
      "[I 2023-09-04 10:45:56,393] Trial 33 finished with value: 0.9225633383010432 and parameters: {'lg__C': 0.22536233948408926, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:45:58,947] Trial 34 finished with value: 0.922702434177844 and parameters: {'lg__C': 7.349792028908774, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:45:59,832] Trial 35 finished with value: 0.92274217585693 and parameters: {'lg__C': 15.662992555554768, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:46:12,493] Trial 36 finished with value: 0.9226229508196722 and parameters: {'lg__C': 0.3558909533495901, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:46:13,346] Trial 37 finished with value: 0.922762046696473 and parameters: {'lg__C': 59.64095881162597, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:46:20,521] Trial 38 finished with value: 0.922702434177844 and parameters: {'lg__C': 7.017621033258743, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:46:21,402] Trial 39 finished with value: 0.92274217585693 and parameters: {'lg__C': 26.10295311716874, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:46:22,299] Trial 40 finished with value: 0.92274217585693 and parameters: {'lg__C': 13.030892542908967, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:46:38,986] Trial 41 finished with value: 0.92274217585693 and parameters: {'lg__C': 1.1135409257667217, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:46:51,300] Trial 42 finished with value: 0.922702434177844 and parameters: {'lg__C': 6.359524428790067, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:47:08,227] Trial 43 finished with value: 0.9226626924987581 and parameters: {'lg__C': 0.565403474350497, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:47:10,260] Trial 44 finished with value: 0.92274217585693 and parameters: {'lg__C': 6.934717271909247, 'lg__penalty': 'l2'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:47:11,181] Trial 45 finished with value: 0.92274217585693 and parameters: {'lg__C': 12.044039295123738, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:47:13,502] Trial 46 finished with value: 0.92274217585693 and parameters: {'lg__C': 5.057686949052607, 'lg__penalty': 'l2'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:47:27,697] Trial 47 finished with value: 0.922702434177844 and parameters: {'lg__C': 5.268647863358133, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:47:29,743] Trial 48 finished with value: 0.92274217585693 and parameters: {'lg__C': 15.863078409462169, 'lg__penalty': 'l2'}. Best is trial 33 with value: 0.9225633383010432.\n",
      "[I 2023-09-04 10:47:42,414] Trial 49 finished with value: 0.922702434177844 and parameters: {'lg__C': 4.446333402589861, 'lg__penalty': 'l1'}. Best is trial 33 with value: 0.9225633383010432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 0.92\n",
      "ROC-AUC do modelo: 0.96\n",
      "Matriz de Confusão:\n",
      "[[ 8878   541]\n",
      " [ 1103 11046]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50) \n",
    "best_params = study.best_params\n",
    "\n",
    "pipeline_lg.set_params(**best_params)\n",
    "pipeline_lg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lg = pipeline_lg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_lg)\n",
    "print(f'Acurácia do modelo: {accuracy:.2f}')\n",
    "\n",
    "y_prob_lg = pipeline_lg.predict_proba(X_test)[:, 1]\n",
    "roc_auc_lg = roc_auc_score(y_test, y_prob_lg)\n",
    "print(f'ROC-AUC do modelo: {roc_auc_lg:.2f}')\n",
    "\n",
    "conf_matrix_lg = confusion_matrix(y_test, y_pred_lg)\n",
    "print('Matriz de Confusão:')\n",
    "print(conf_matrix_lg)\n",
    "\n",
    "fpr_lg, tpr_lg, _ = roc_curve(y_test, y_prob_lg)\n",
    "roc_auc_lg = auc(fpr_lg, tpr_lg)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lg, tpr_lg, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_lg))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('rf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'rf__n_estimators': trial.suggest_int('rf__n_estimators', 50, 200),\n",
    "        'rf__max_depth': trial.suggest_int('rf__max_depth', 5, 30),\n",
    "        'rf__min_samples_split': trial.suggest_float('rf__min_samples_split', 0.1, 1.0),\n",
    "        'rf__min_samples_leaf': trial.suggest_float('rf__min_samples_leaf', 0.1, 0.5),\n",
    "    }\n",
    "    pipeline_rf.set_params(**params)\n",
    "    cv_scores = cross_val_score(pipeline_rf, X_train, y_train, cv=5)\n",
    "    return cv_scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 10:50:20,213] A new study created in memory with name: no-name-00f56de0-4088-40d0-9e13-3ce8654ee0a9\n",
      "[I 2023-09-04 10:50:27,248] Trial 0 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 152, 'rf__max_depth': 17, 'rf__min_samples_split': 0.9279231706085953, 'rf__min_samples_leaf': 0.32289402897269515}. Best is trial 0 with value: 0.5544162940884252.\n",
      "[I 2023-09-04 10:50:36,527] Trial 1 finished with value: 0.6939890710382514 and parameters: {'rf__n_estimators': 142, 'rf__max_depth': 17, 'rf__min_samples_split': 0.279084416574072, 'rf__min_samples_leaf': 0.21110178931349155}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:50:42,490] Trial 2 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 126, 'rf__max_depth': 24, 'rf__min_samples_split': 0.9977747698760847, 'rf__min_samples_leaf': 0.32454273416077206}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:50:47,491] Trial 3 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 139, 'rf__max_depth': 28, 'rf__min_samples_split': 0.44252153199288147, 'rf__min_samples_leaf': 0.39471279239168455}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:50:54,731] Trial 4 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 175, 'rf__max_depth': 12, 'rf__min_samples_split': 0.8108906720035788, 'rf__min_samples_leaf': 0.3100272302404702}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:00,441] Trial 5 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 148, 'rf__max_depth': 13, 'rf__min_samples_split': 0.6447939237852183, 'rf__min_samples_leaf': 0.1608521106478639}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:07,486] Trial 6 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 184, 'rf__max_depth': 19, 'rf__min_samples_split': 0.9071301633242592, 'rf__min_samples_leaf': 0.13656147685982642}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:11,825] Trial 7 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 114, 'rf__max_depth': 19, 'rf__min_samples_split': 0.6807125029840433, 'rf__min_samples_leaf': 0.12010362213761963}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:15,507] Trial 8 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 103, 'rf__max_depth': 17, 'rf__min_samples_split': 0.8391946138795588, 'rf__min_samples_leaf': 0.4090219124425277}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:23,363] Trial 9 finished with value: 0.6729259811227024 and parameters: {'rf__n_estimators': 152, 'rf__max_depth': 18, 'rf__min_samples_split': 0.4345834391495347, 'rf__min_samples_leaf': 0.26841127046462865}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:26,932] Trial 10 finished with value: 0.6797218082463984 and parameters: {'rf__n_estimators': 66, 'rf__max_depth': 7, 'rf__min_samples_split': 0.12758590445117013, 'rf__min_samples_leaf': 0.21483212167128574}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:29,945] Trial 11 finished with value: 0.6748534525583706 and parameters: {'rf__n_estimators': 59, 'rf__max_depth': 5, 'rf__min_samples_split': 0.14720652684109456, 'rf__min_samples_leaf': 0.22051371830122785}. Best is trial 1 with value: 0.6939890710382514.\n",
      "[I 2023-09-04 10:51:34,289] Trial 12 finished with value: 0.6979234972677595 and parameters: {'rf__n_estimators': 79, 'rf__max_depth': 7, 'rf__min_samples_split': 0.11650013568293996, 'rf__min_samples_leaf': 0.2082075000561165}. Best is trial 12 with value: 0.6979234972677595.\n",
      "[I 2023-09-04 10:51:39,175] Trial 13 finished with value: 0.6957575757575757 and parameters: {'rf__n_estimators': 88, 'rf__max_depth': 10, 'rf__min_samples_split': 0.2786683815538796, 'rf__min_samples_leaf': 0.2114203890966624}. Best is trial 12 with value: 0.6979234972677595.\n",
      "[I 2023-09-04 10:51:42,447] Trial 14 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 85, 'rf__max_depth': 9, 'rf__min_samples_split': 0.22984029534945954, 'rf__min_samples_leaf': 0.45984751161894766}. Best is trial 12 with value: 0.6979234972677595.\n",
      "[I 2023-09-04 10:51:48,072] Trial 15 finished with value: 0.9090312965722802 and parameters: {'rf__n_estimators': 86, 'rf__max_depth': 10, 'rf__min_samples_split': 0.2951099204622476, 'rf__min_samples_leaf': 0.10557811665488223}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:51:53,094] Trial 16 finished with value: 0.9038052657724789 and parameters: {'rf__n_estimators': 78, 'rf__max_depth': 5, 'rf__min_samples_split': 0.3418094506302577, 'rf__min_samples_leaf': 0.10557896045407283}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:51:56,980] Trial 17 finished with value: 0.8891008445106806 and parameters: {'rf__n_estimators': 53, 'rf__max_depth': 5, 'rf__min_samples_split': 0.3985255686022268, 'rf__min_samples_leaf': 0.11460359120270018}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:02,194] Trial 18 finished with value: 0.8953005464480874 and parameters: {'rf__n_estimators': 102, 'rf__max_depth': 13, 'rf__min_samples_split': 0.5244327576617164, 'rf__min_samples_leaf': 0.10649958879937772}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:06,493] Trial 19 finished with value: 0.7716244411326378 and parameters: {'rf__n_estimators': 73, 'rf__max_depth': 10, 'rf__min_samples_split': 0.3477415767352958, 'rf__min_samples_leaf': 0.16606300658829068}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:14,241] Trial 20 finished with value: 0.7635370094386488 and parameters: {'rf__n_estimators': 97, 'rf__max_depth': 14, 'rf__min_samples_split': 0.33737959190734784, 'rf__min_samples_leaf': 0.1606650160720936}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:20,464] Trial 21 finished with value: 0.9040238450074515 and parameters: {'rf__n_estimators': 109, 'rf__max_depth': 14, 'rf__min_samples_split': 0.495811128701648, 'rf__min_samples_leaf': 0.10130928898131199}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:28,439] Trial 22 finished with value: 0.9080377545951317 and parameters: {'rf__n_estimators': 118, 'rf__max_depth': 8, 'rf__min_samples_split': 0.48551821154706976, 'rf__min_samples_leaf': 0.10755298146960215}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:35,916] Trial 23 finished with value: 0.7707103825136612 and parameters: {'rf__n_estimators': 124, 'rf__max_depth': 8, 'rf__min_samples_split': 0.5177311048674069, 'rf__min_samples_leaf': 0.14822387962378436}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:42,057] Trial 24 finished with value: 0.8851266766020863 and parameters: {'rf__n_estimators': 112, 'rf__max_depth': 15, 'rf__min_samples_split': 0.5955270440833532, 'rf__min_samples_leaf': 0.1402819592910292}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:49,014] Trial 25 finished with value: 0.9034674615002484 and parameters: {'rf__n_estimators': 122, 'rf__max_depth': 21, 'rf__min_samples_split': 0.49441500788782167, 'rf__min_samples_leaf': 0.104158726261078}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:52:57,163] Trial 26 finished with value: 0.7313263785394932 and parameters: {'rf__n_estimators': 168, 'rf__max_depth': 11, 'rf__min_samples_split': 0.5918642195651309, 'rf__min_samples_leaf': 0.17411612523102427}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:03,109] Trial 27 finished with value: 0.9029706905116741 and parameters: {'rf__n_estimators': 90, 'rf__max_depth': 15, 'rf__min_samples_split': 0.46503601403991573, 'rf__min_samples_leaf': 0.1006314202528591}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:10,299] Trial 28 finished with value: 0.7751813214108296 and parameters: {'rf__n_estimators': 135, 'rf__max_depth': 11, 'rf__min_samples_split': 0.40996320299865513, 'rf__min_samples_leaf': 0.181569773935566}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:16,382] Trial 29 finished with value: 0.8642026825633383 and parameters: {'rf__n_estimators': 107, 'rf__max_depth': 8, 'rf__min_samples_split': 0.5658341072771671, 'rf__min_samples_leaf': 0.13582996562545468}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:26,266] Trial 30 finished with value: 0.8944063586686537 and parameters: {'rf__n_estimators': 198, 'rf__max_depth': 15, 'rf__min_samples_split': 0.4801053333612118, 'rf__min_samples_leaf': 0.13205261553489797}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:31,677] Trial 31 finished with value: 0.9031097863884749 and parameters: {'rf__n_estimators': 76, 'rf__max_depth': 6, 'rf__min_samples_split': 0.37989509005139604, 'rf__min_samples_leaf': 0.1001030872922557}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:37,551] Trial 32 finished with value: 0.8865573770491804 and parameters: {'rf__n_estimators': 93, 'rf__max_depth': 9, 'rf__min_samples_split': 0.3292383785399258, 'rf__min_samples_leaf': 0.1350762779973247}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:41,251] Trial 33 finished with value: 0.7576751117734725 and parameters: {'rf__n_estimators': 65, 'rf__max_depth': 5, 'rf__min_samples_split': 0.2727479350748966, 'rf__min_samples_leaf': 0.18848788385667137}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:48,758] Trial 34 finished with value: 0.7737307501241928 and parameters: {'rf__n_estimators': 117, 'rf__max_depth': 7, 'rf__min_samples_split': 0.3859797269353097, 'rf__min_samples_leaf': 0.15160940012206134}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:53:56,726] Trial 35 finished with value: 0.8706408345752609 and parameters: {'rf__n_estimators': 132, 'rf__max_depth': 30, 'rf__min_samples_split': 0.20947822006073838, 'rf__min_samples_leaf': 0.1250474244541652}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:01,231] Trial 36 finished with value: 0.8860407352210631 and parameters: {'rf__n_estimators': 80, 'rf__max_depth': 12, 'rf__min_samples_split': 0.4460899927669286, 'rf__min_samples_leaf': 0.12180428736443921}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:07,471] Trial 37 finished with value: 0.7683656234475906 and parameters: {'rf__n_estimators': 97, 'rf__max_depth': 9, 'rf__min_samples_split': 0.3480186408369068, 'rf__min_samples_leaf': 0.1544009266143786}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:13,493] Trial 38 finished with value: 0.7640139095876799 and parameters: {'rf__n_estimators': 108, 'rf__max_depth': 26, 'rf__min_samples_split': 0.30057796682740356, 'rf__min_samples_leaf': 0.18650278411637922}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:21,182] Trial 39 finished with value: 0.6565722801788376 and parameters: {'rf__n_estimators': 141, 'rf__max_depth': 22, 'rf__min_samples_split': 0.43534805062748644, 'rf__min_samples_leaf': 0.2396009156729989}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:24,642] Trial 40 finished with value: 0.8605663189269747 and parameters: {'rf__n_estimators': 66, 'rf__max_depth': 12, 'rf__min_samples_split': 0.5495383321521425, 'rf__min_samples_leaf': 0.11954397763860873}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:31,135] Trial 41 finished with value: 0.9000496770988574 and parameters: {'rf__n_estimators': 123, 'rf__max_depth': 22, 'rf__min_samples_split': 0.49076053238466727, 'rf__min_samples_leaf': 0.10172795496132085}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:37,937] Trial 42 finished with value: 0.8914456035767511 and parameters: {'rf__n_estimators': 118, 'rf__max_depth': 22, 'rf__min_samples_split': 0.49544895081294416, 'rf__min_samples_leaf': 0.12090662270767358}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:42,382] Trial 43 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 131, 'rf__max_depth': 21, 'rf__min_samples_split': 0.6564414210210308, 'rf__min_samples_leaf': 0.10043715675963034}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:51,967] Trial 44 finished with value: 0.7547342275211127 and parameters: {'rf__n_estimators': 161, 'rf__max_depth': 20, 'rf__min_samples_split': 0.4194615238418079, 'rf__min_samples_leaf': 0.14710157557269693}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:54:59,547] Trial 45 finished with value: 0.7460307998012915 and parameters: {'rf__n_estimators': 147, 'rf__max_depth': 17, 'rf__min_samples_split': 0.45147011623823624, 'rf__min_samples_leaf': 0.16893510115417895}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:55:05,431] Trial 46 finished with value: 0.877933432687531 and parameters: {'rf__n_estimators': 99, 'rf__max_depth': 6, 'rf__min_samples_split': 0.37153116707404704, 'rf__min_samples_leaf': 0.12211138557809681}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:55:09,765] Trial 47 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 107, 'rf__max_depth': 25, 'rf__min_samples_split': 0.7015971858532122, 'rf__min_samples_leaf': 0.14067625514195325}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:55:11,652] Trial 48 finished with value: 0.5544162940884252 and parameters: {'rf__n_estimators': 50, 'rf__max_depth': 18, 'rf__min_samples_split': 0.5155421754928402, 'rf__min_samples_leaf': 0.33743003454537734}. Best is trial 15 with value: 0.9090312965722802.\n",
      "[I 2023-09-04 10:55:16,455] Trial 49 finished with value: 0.8919821162444113 and parameters: {'rf__n_estimators': 85, 'rf__max_depth': 8, 'rf__min_samples_split': 0.4106003805139161, 'rf__min_samples_leaf': 0.12092512791716581}. Best is trial 15 with value: 0.9090312965722802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Random Forest: 0.91\n",
      "ROC-AUC do modelo Random Forest: 0.95\n",
      "Matriz de Confusão Random Forest:\n",
      "[[ 8286  1133]\n",
      " [  781 11368]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAIhCAYAAACot7njAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACX0ElEQVR4nOzdd1iT198G8DuEkLBBUBQn7r1woVK3VdzaahX3qKPVVu2v1Vq1altb9x7FvW1VrPpq1dYtbnEVrQvFAaIgeyfn/SMSiKAlmvAAuT/XlSsnJ0+SO8Hx5eQ858iEEAJERERERAWchdQBiIiIiIhyAwtfIiIiIjILLHyJiIiIyCyw8CUiIiIis8DCl4iIiIjMAgtfIiIiIjILLHyJiIiIyCyw8CUiIiIis8DCl4iIiIjMAgtfInqja9euYdCgQfDw8IBKpYKdnR3q1q2LWbNmITIyUup470Qmk+ldHBwc0LhxY2zduvWNjzl79iw+/vhjFCtWDFZWVihatCg++ugjnDlz5o2PeZ/P7vvvv9fLqFAoUKpUKQwbNgxhYWHv/N7f18CBA1GmTBnJXv9169aty/LzTL989dVXUsfL1k8//YTdu3dLHYPIbFlKHYCI8iY/Pz+MGjUKlSpVwv/+9z9UrVoVqampuHjxIlasWIEzZ87A399f6pjv5KOPPsL48eMhhEBwcDB++ukn9OnTB0II9OnTR+/YxYsX48svv0SDBg0wa9YslC5dGiEhIVi6dCmaNm2KhQsX4vPPP9d7jLE+uz///BOOjo6Ii4vDoUOHMHfuXAQEBODKlStQKBRG/Uzys7Vr16Jy5cp6fe7u7hKlebuffvoJH330Ebp27Sp1FCLzJIiIXhMQECDkcrlo166dSEpKynJ/cnKy+OOPP4zyWgkJCUKj0RjluXICgPjss8/0+h48eCAAiA8++ECv/9SpU8LCwkJ07NhRpKam6t2XmpoqOnbsKCwsLMSpU6d0/cb47KZOnSoAiOfPn+v1Dxo0SAAQR44cydF7NbYBAwaI0qVLS/La2Vm7dq0AIC5cuGCS54+Pjzf6c9ra2ooBAwYY/XmJKGc41YGIsvjpp58gk8nw66+/QqlUZrnfysoKnTt31t2WyWT4/vvvsxxXpkwZDBw4UHc7/avpQ4cOYfDgwShcuDBsbGywfft2yGQy/P3331meY/ny5ZDJZLh27RoA4OLFi/jkk09QpkwZWFtbo0yZMujduzcePnz4zu+3dOnSKFy4MJ49e6bXP3PmTMhkMixfvhyWlvpfkFlaWmLZsmWQyWT4+eefdf2GfnaGqFevHgDo5Xz+/DlGjRqFqlWrws7ODkWKFEHLli1x8uRJvcc+ePAAMpkMc+bMwbx58+Dh4QE7Ozt4eXnh7NmzWV5r3bp1qFSpEpRKJapUqYINGzZkmykyMhKjRo1C8eLFYWVlhbJly2LSpElITk7WO04mk+Hzzz/H2rVrUalSJVhbW6NevXo4e/YshBCYPXu2LlPLli1x9+7dd/qMsrNnzx54eXnBxsYG9vb2aNOmTZZpKunTSy5fvoyPPvoIzs7OKFeuHABACIFly5ahdu3asLa2hrOzMz766CPcv39f7zkCAwPRsWNHFClSBEqlEu7u7ujQoQMeP36s+wzi4+Oxfv163ZSM5s2bG+19EtF/41QHItKjVqtx5MgReHp6omTJkiZ5jcGDB6NDhw7YuHEj4uPjdcXC2rVr0apVK71j161bh7p166JmzZoAtAVcpUqV8Mknn6BQoUIIDQ3F8uXLUb9+fQQFBcHV1dXgPNHR0YiMjESjRo10fWq1GkePHkW9evVQokSJbB9XsmRJeHp64siRI1Cr1QBg0s8uODgYAFCxYkVdX/p84alTp6Jo0aKIi4uDv78/mjdvjr///jtLYbV06VJUrlwZCxYsAABMnjwZPj4+CA4OhqOjIwDtZz5o0CB06dIFc+fORXR0NL7//nskJyfDwiJjvCQpKQktWrTAvXv3MG3aNNSsWRMnT57EzJkzceXKFfzf//2f3mvv27cPgYGB+PnnnyGTyfDNN9+gQ4cOGDBgAO7fv48lS5YgOjoa48aNQ48ePXDlyhXIZLL//FzUajXS0tL0+tJ/UdmyZQt8fX3Rtm1bbN26FcnJyZg1a5bu82natKne47p3745PPvkEI0aMQHx8PABg+PDhWLduHcaMGYNffvkFkZGRmD59Oho3boyrV6/Czc0N8fHxaNOmDTw8PLB06VK4ubkhLCwMR48eRWxsLADgzJkzaNmyJVq0aIHJkycDABwcHP7z/RGREUk95ExEeUtYWJgAID755JMcPwaAmDp1apb+0qVL632tm/7VdP/+/bMcO27cOGFtbS2ioqJ0fUFBQQKAWLx48RtfOy0tTcTFxQlbW1uxcOHCHGUdNWqUSE1NFSkpKeL27duic+fOwt7eXly8eFF3XE4/h169egkA4tmzZ+/02WUnfapDWFiYSE1NFS9fvhS//fabsLW1Fb17937rY9PS0kRqaqpo1aqV6Natm64/ODhYABA1atQQaWlpuv7z588LAGLr1q1CCCHUarVwd3cXdevW1ZuC8uDBA6FQKPSmOqxYsUIAEL/99ptehl9++UUAEIcOHdL1ARBFixYVcXFxur7du3cLAKJ27dp6r7VgwQIBQFy7du2t7zX9z1N2l9TUVN17qVGjhlCr1brHxcbGiiJFiojGjRvr+tI/8ylTpui9xpkzZwQAMXfuXL3+R48eCWtra/H1118LIYS4ePGiACB279791syc6kAkLU51IKJc16NHjyx9gwcPRmJiIrZv367rW7t2LZRKpd4JZ3Fxcfjmm29Qvnx5WFpawtLSEnZ2doiPj8fNmzdz9PrLli2DQqGAlZUVKlasiAMHDmDr1q3w9PQ0+L0IIQAgRyOThipatCgUCgWcnZ3Rs2dPeHp6Yv369VmOW7FiBerWrQuVSgVLS0soFAr8/fff2X4eHTp0gFwu191OH0lPnyry77//4unTp+jTp4/eeypdujQaN26s91xHjhyBra0tPvroI73+9Oktr09dadGiBWxtbXW3q1SpAgBo37693mul9+d0+sqGDRtw4cIFvYulpaXuvfTr109vpNrOzg49evTA2bNnkZCQoPdcr//Z3LdvH2QyGfr27Yu0tDTdpWjRoqhVqxaOHTsGAChfvjycnZ3xzTffYMWKFQgKCspRdiLKXSx8iUiPq6srbGxsdF+rm0KxYsWy9FWrVg3169fH2rVrAWi/vt60aRO6dOmCQoUK6Y7r06cPlixZgqFDh+LgwYM4f/48Lly4gMKFCyMxMTFHr9+zZ09cuHABAQEBWLlyJezt7fHJJ5/gzp07umNy+jk8ePAANjY2KFSokNE/u7/++gsXLlzAwYMH0aNHD5w4cQKjR4/WO2bevHkYOXIkGjZsiJ07d+Ls2bO4cOEC2rVrl+3n4eLionc7fR5y+rEREREAtEX3617vi4iIQNGiRbMU/UWKFIGlpaXuudJl/jkC2vnOb+tPSkrKkiE7VapUQb169fQumd9Ldn/e3N3dodFo8PLlS73+14999uwZhBBwc3ODQqHQu5w9exYvXrwAADg6OuL48eOoXbs2vv32W1SrVg3u7u6YOnUqUlNTc/Q+iMj0OMeXiPTI5XK0atUKBw4cwOPHj984vzUzpVKZ5WQmAFkKn3RvGh0dNGgQRo0ahZs3b+L+/fsIDQ3FoEGDdPdHR0dj3759mDp1KiZMmKDrT05ONmhd4cKFC+uKIy8vL1SpUgXNmjXD2LFjsW/fPgDaz6FFixb4888/3/g5PH78GJcuXUL79u11o6iGfnZvU6tWLd2c5TZt2uDDDz/Er7/+iiFDhqB+/foAgE2bNqF58+ZYvny53mPT55UaKr0wzm694Nf7XFxccO7cOQgh9H6m4eHhSEtLe6f51saU/l5CQ0Oz3Pf06VNYWFjA2dlZr//1P5uurq6QyWQ4efJkticrZu6rUaMGtm3bBiEErl27hnXr1mH69OmwtrbW+/NKRNLhiC8RZTFx4kQIITBs2DCkpKRkuT81NRV79+7V3S5Tpoxu1YV0R44cQVxcnEGv27t3b6hUKqxbtw7r1q1D8eLF0bZtW939MpkMQogsBciqVat0J5e9C29vb/Tv3x//93//p3e2f/rnMGrUqCzPr1arMXLkSAghMHHixCyPyelnl1MymQxLly6FXC7Hd999p9f/+udx7dq1t26u8TaVKlVCsWLFsHXrVt00DkA77SAgIEDv2FatWiEuLi7LhgzpK0C8fqJibqtUqRKKFy+OLVu26L2X+Ph47Ny5U7fSw9t07NgRQgg8efIky6hyvXr1UKNGjSyPkclkqFWrFubPnw8nJydcvnxZd59SqczxNxNEZHwc8SWiLLy8vLB8+XKMGjUKnp6eGDlyJKpVq4bU1FQEBgbi119/RfXq1dGpUycAQL9+/TB58mRMmTIFzZo1Q1BQEJYsWaJbJSCnnJyc0K1bN6xbtw5RUVH46quv9OZmOjg44IMPPsDs2bPh6uqKMmXK4Pjx41i9ejWcnJze6z3PmDED27dvx+TJk/HXX38BAJo0aYIFCxbgyy+/RNOmTfH555+jVKlSug0szp07hwULFujNfTX0szNEhQoV8Omnn2LZsmU4deoUmjZtio4dO2LGjBmYOnUqmjVrhn///RfTp0+Hh4dHlpUOcsLCwgIzZszA0KFD0a1bNwwbNgxRUVH4/vvvs0x16N+/P5YuXYoBAwbgwYMHqFGjBk6dOoWffvoJPj4+aN26tcGvb0wWFhaYNWsWfH190bFjRwwfPhzJycmYPXs2oqKi9Jahe5MmTZrg008/xaBBg3Dx4kV88MEHsLW1RWhoKE6dOoUaNWpg5MiR2LdvH5YtW4auXbuibNmyEEJg165diIqKQps2bXTPV6NGDRw7dgx79+5FsWLFYG9vj0qVKpnyYyCizCQ5pY6I8oUrV66IAQMGiFKlSgkrKytha2sr6tSpI6ZMmSLCw8N1xyUnJ4uvv/5alCxZUlhbW4tmzZqJK1euvHFVh7dtOHDo0CHdmfm3b9/Ocv/jx49Fjx49hLOzs7C3txft2rUTN27cyPJab4JsNrBI97///U8AEMePH9frP3PmjPjoo4+Em5ubsLS0FEWKFBHdu3cXAQEBb3ydnH522XnTBhZCCPHs2TNhZ2cnWrRoIYTQfvZfffWVKF68uFCpVKJu3bpi9+7dWTabSF/VYfbs2dl+Jq+vyrFq1SpRoUIFYWVlJSpWrCjWrFmT7QYWERERYsSIEaJYsWLC0tJSlC5dWkycODHL5h3Zfe5vynT06FEBQPz+++9v/ZxyuoHF7t27RcOGDYVKpRK2traiVatW4vTp03rHvO0zF0KINWvWiIYNGwpbW1thbW0typUrJ/r3769bCeTWrVuid+/eoly5csLa2lo4OjqKBg0aiHXr1uk9z5UrV0STJk2EjY2NACCaNWv21uxEZFwyITJ9/0NEREREVEBxji8RERERmQUWvkRERERkFlj4EhEREZFZYOFLRERERGaBhS8RERERmQUWvkRERERkFsxuAwuNRoOnT5/C3t7+jdumEhEREZF0hBCIjY2Fu7u73kZG78vsCt+nT5+iZMmSUscgIiIiov/w6NEjlChRwmjPZ3aFr729PQDtB+ng4CBxGiIiIiJ6XUxMDEqWLKmr24zF7Arf9OkNDg4OLHyJiIiI8jBjT0vlyW1EREREZBZY+BIRERGRWWDhS0RERERmgYUvEREREZkFFr5EREREZBZY+BIRERGRWWDhS0RERERmgYUvEREREZkFFr5EREREZBZY+BIRERGRWWDhS0RERERmgYUvEREREZkFFr5EREREZBZY+BIRERGRWWDhS0RERERmQdLC98SJE+jUqRPc3d0hk8mwe/fu/3zM8ePH4enpCZVKhbJly2LFihWmD0pERERE+Z6khW98fDxq1aqFJUuW5Oj44OBg+Pj4wNvbG4GBgfj2228xZswY7Ny508RJiYiIiCi/s5Tyxdu3b4/27dvn+PgVK1agVKlSWLBgAQCgSpUquHjxIubMmYMePXqYKCURERER5YgQgDoZSE0A0hLffnnLMTeuJZoknqSFr6HOnDmDtm3b6vV9+OGHWL16NVJTU6FQKLI8Jjk5GcnJybrbMTExJs9JRERElGdp0oCUOCA1DkiJfXUdl+k69rXbr45LS/jPghVpSQDEO0eLSVLic38fbLxUyXjvN5N8VfiGhYXBzc1Nr8/NzQ1paWl48eIFihUrluUxM2fOxLRp03IrIhEREZFxpCUBiRFAUoT2OjVO26dOyigy01611ZnaaQnaQjW9aE0vYNOLXHXyf7+2BE4Hl0TfLd3x4KUzgCSTvEa+KnwBQCaT6d0WQmTbn27ixIkYN26c7nZMTAxKlixpuoBEREREQqMtNJOjtCOk8WFAzEPtJfkloE4FNJku6hQg6WVGkZv4QlvA5mWWKsDSOtPF5rXbry6KN/S/ui8NKsxYHokflj+FRqN9ans7BWLjTBDZ+E9pOkWLFkVYWJheX3h4OCwtLeHi4pLtY5RKJZRKZW7EIyIiooJEaICkqIxi9E3X6mTtSGrSS22hmxwFJEdrH58XWNoAVnaAwi7Ttb3+7fQ+vduZjlPYvSpg04tYJSB7/zUS7t2LhK/vLpw791TX17RpKSxb1go1a8547+d/Xb4qfL28vLB37169vkOHDqFevXrZzu8lIiIiMySEdhQ1NQFIfA7EPwMSwl5dv7okRmhHWdXJ2pHV1ITsr3ObTA5YuwDWroDKRb9tZZ8xyipXvWq/dluuAhS2mQpYW8BCnvvv4z8IIbB+/VWMHn0AcXEpAAC5XIZp05pjwoSmiI83wXAvJC584+LicPfuXd3t4OBgXLlyBYUKFUKpUqUwceJEPHnyBBs2bAAAjBgxAkuWLMG4ceMwbNgwnDlzBqtXr8bWrVulegtERERkDEJoC83YJ9oiNfaRtgjUnWyV6ZLwTFvEps9rff36PU+wemcWloDSCVA5a6/TLwobQOUKOJTWXmyKAHIFYJHpIldoj7VyAN4wfbMg0WgEVq8O1BW95co5Y/Pm7mjYsIRJX1fSwvfixYto0aKF7nb6XNwBAwZg3bp1CA0NRUhIiO5+Dw8P7N+/H2PHjsXSpUvh7u6ORYsWcSkzIiIiKaQlAdEPtIVpUhSQEq0dRU2fs5qWCMQ+1t6fGv+qiI1/dcJVpuv0fimK1XQWioyv8jNfK50yRl5fv05vW6pejcbamEXRagxyuQU2buyGWrVW4OOPq2LBgnaws7My+evKRPrZYWYiJiYGjo6OiI6OhoODg9RxiIiITC99NDUl9tVX+0naa3UykJasHSnV3X61MkBKTEbhGvdEe1u3SkC89pIcJe08VrmV/lf8lipArtS/be0K2LhpL7aZrq0Lv5oioHx1zSmTppSSosbjxzEoW9ZZr//JkxgUL561HjNVvZav5vgSERGZJaEBkmMynTgVpR1hTc7mkn6CVeYTrVITAKGWJvubyJUZc1CtXl0r7LSFqv2r1Zc0aYBrjYyTrKzsAYU9YF0IsCuunVpAed6tWy/g67sL0dFJCAwcDnv7jEUHsit6TYl/YoiIiN5VWrJ2JDQ5Wvs1f3K0dlRVkwpo1IBI0xZv2bXTErXFafooa/oIqm5DgUwbC6Ql5I0VAmQWrwrUVxelM+Bc4dWJV3baa7mV9mJhpR1FtS0GqAplWkHg1WNZtBZ4QgisXHkJ48YdRGJiGgBg3LiD8PPrLFkm/qkjIiLzkr6lqu5kqRj9r/Ez71yVEpMxepo+gppe4CZH59mNAABoR1TTT7JS2AJKR23xKVdpl6KSv5oWoJsa8Nq1laO2gLVzB+xKaItXSxXnsFKOhIfHY+jQPdi797aur0oVV3z2WQMJU7HwJSKi/EAI7aiorkiN0X71r9eOzrhOiQMSwjPmrSY+fzVymqgdWc1rX/u/zkKRaf3UVyOkKmftCKvKKWO1gNdXD1A6ae+3cgQU1tLlJ7N24MAdDBr0B549i9f1ffZZfcya1QY2NtLOpWbhS0REppW+pqpGrR1RjXmgnZ+a+qo4vbdHe8JRWiKgSdHuaJUa+2qENTqjuNWkSf1OAMi0I6fpFyuHV9eZ++y1X/NbWGqX47KwzL4tV2jns6afYCVXaUdVrey1I7JE+UxiYiq++eYvLF58XtdXpIgt1qzpjA4dKkqYLAMLXyKigk5oXn1VH5mx1FT6clOa1Gy2Ts3UTngOxIe+mm8a+6o4TcvmcWn6j399XVWpWTloR0fTt1XNvCNVegGrt5NVph2sVM4ZI6tW9kbZrYqooFGrNfD2XotLl0J1fT4+FbBmTWe4udlJmEwfC18iIlPTqDMtIZXNQvvq5NduZ3dMDo9VJ78qcJNfnUSl0d6XF06MMpgMUDpoR0WtHDKNrqa3Hd7QdtRODbB21V7LrVisEpmYXG6Bvn1r4tKlUKhUlpgzpw1GjaoPWR6bE87Cl4jMhxDauZ2Z1yrVFY2JGcVkltHPlFcnOqWfCBWbdSep9H7diGia9sx9dWren0/6vmQW+rtPWSiybqequ1/5aueqwq/mr9plFLeFKr9aCcBKe6ylNb/yJ8pHxoxpiAcPovDpp56oWrWw1HGyxcKXiKQhBBAfpi0U1SmvRihTtMtDaVIy+lJigaQIIPGF9uv61AQgMgiIewrYFtXOEU1L0haXQpPpOlM7feRTyl2hcoPubHwH7df5FnJtUSp/tYh/+ln5WYpUq6xbp1ootEWo0kG7pmr6VID0IlZ3jCVHU4nM0O7dtxAU9Bzffuut67OwkGHBgnYSpvpvLHyJKOfSkrVnzKefXf/6mfTpZ9mn7+yUFJnp6/mUjDPsUxNezRuNeb88sY+M876MQZE+Z9QGkFm+dhKTMmP08/VdprL0KXNwTKYdqnT9/DqfiEwvPj4FY8cehJ/fZchkgJdXCbRo4SF1rBxj4UtkjoR4NZIamVGMxoQAcY+1xWvii4xLUqT2LPy4J1Knzp51Ye08TpnFq8urUc700c7025nbugLSOpu2MmMENPNIqO6EJ3vtKGh62+rVSVAsOomogLt48Sl8fXfh9u0IANr/SnbsCGLhS0S5TAjt6GlihLZIjX/22jam0cD9/9POq0yJAeJCtTtBSSF9nqfSCXAqq912NL3YlCsz5nim96WfpGTt8mr3J1vt1/iW1tp+C7k074OIyEyo1RrMmnUaU6YcQ1qa9kRZGxsFFi1qh8GD60iczjAsfInyCqHRnkAVehZ4fk17clRqHBAbkmnZqVfXqQnA8yvar9fjQ//zqXXiHr9bNoWd9oQkVSHgxTXAzRNwKPPaOqaZrhV22q/8Vc7aIjVzIcuRUSKifCMkJBr9+vnjxImHur769d2xeXN3VKjgImGyd8PCl8jY0pK1c09jHgLxT7VzXVPiMm1zGvWG62gYfPJVSuy7ZSxUBbArBqhcMr7qlyu10xqK1gOK1Hk1yuqq3SmKZ9YTEZmd7dtvYPjwfYiO1m7NbWEhw8SJTTF1ajMoFPnz2zYWvkRvIzRA9ANtQZi+5WncY+1KAokRr1YbeHWdHK0doU2KQq6uHuDood016vkVoGwnwLkiYF9cW7Cmb1+avpWptat2PioREdFbqNUazJlzRlf0li7tiI0bu8Hbu7TEyd4PC18qWDRq7XSAlGhtQZoapy1WU+MyteOz9mdefSB9xQJ1csZzmIrcKqMoVTpqr9MX7a/sq10VwKGUdvpAdidcWVgCeWxxcCIiyv/kcgts3twddeqsRLdulbF0qQ8cHVVSx3pvLHwpb9KotWu2pq84kL4bVeIL/ZHW5JfaE7liHgKxD7WPkYKlKmM7U6Wzdj6sQ2nAvsSrOa+2+sVt+rVl/v9HhIiI8r+0NA3CwuJQooSDrq9iRRdcvz4SZcs6S5jMuFj4kukJjbYgjQ8DEp5pC9WEZ9pC9skpbQGYEgPEPgZe/it1WgCyjIX65UrAuQLgXEm7qoCVA2DrBti+mh9r7fJqW1QbqUMTERG9k3v3IuHruwsxMcm4ePFT2NgodPcVpKIXYOFL70oI7Sjr0zPAswvawjY5+rUTuGK00wpyY9ksmVy7u5RtUW2xamUP2BR5taGAnXbEVWH3ai3WTNfp/SqnV6sPKDl9gIiIzIIQAuvXX8Xo0QcQF5cCAPjmm8NYvNhH4mSmw8KX9AmNdmT2+VXtVILEF9oiNumldlpBaoJ2mkH4FW2/Mcnk2lHW1DigUGXterQlmmuXxJIrtaOtNoUzRlpVr9Z1tXbVrlBgwT/OREREOREZmYgRI/bh99+DdH3lyjmjb9+aEqYyPVYKpF0v9txM4N9tQNQ97Xza9yGzeG09V1tt8Wrjph2RtXHTThdQuWTsfGVfSvsYjrQSERGZ1NGjwejXzx9PnmQsiTl4cG0sXNgednZWEiYzPRa+5iotGTjQD4i6C0QEGV7s2hUHitQGCtcGCtcCXKpmnLClsGUBS0RElMekpKjx3XdHMGdOAMSrVTednVXw8+uEHj2qShsul7DwNVcnvgZu/56136Uq4FhWuzasOgUo8YF2tFbppL9drHWhXI9MRERE7yYtTQNv77U4f/6Jrq9lSw+sX99VbyWHgo6FrzkKmAYELsrUIdPu1OX9E1DmQ8liERERkWlYWlqgc+eKOH/+CRQKC/z0UyuMG+cFCwvz+oaWha+5EBrg7h/Anu76/XW/BFrMlyQSERER5Z4JE5oiODgKn31WH3XqFJM6jiRY+JqLednsqd14GtBocu5nISIiIpM6cOAObt+OwBdfNNL1yeUWWLWqs4SppMfC1xz80T1rX8nm2qKXJ6EREREVGImJqfjmm7+wePF5yOUyNGhQHF5eJaWOlWew8C3oXt4B7vrr942O1W7gQERERAXG1ath8PXdhX/+eQ4AUKsFNmy4ysI3Exa+BdmDw8DOtvp9X6YAckX2xxMREVG+o9EILFx4FhMm/I2UFDUAQKWyxJw5bTBqVH2J0+UtLHwLqptbgP2+GbeVTkD/qyx6iYiICpCnT2MxcOBuHD58X9dXs6YbtmzpjmrVikiYLG9i4VvQPLsEbKqn3yezAPqcAxxKSZOJiIiIjM7f/yaGDduLiIhEXd/48V748ceWUCpZ4mWHn0pBcmY6EDBVv8+uOOB7HrBzlyYTERERGV1amgZTphzTFb3Fitlhw4ZuaN26rMTJ8jYWvvlZQjgQeh4I+Ru4vCDr/cW8gF7HAHnB3nebiIjI3FhaWmDLlu6oX98PPj4V4OfXCS4uNlLHyvNY+OZXT88AvzXXbiucnR4HgTJts7+PiIiI8hW1WoMXLxLg5paxKlONGm64fHk4qlRxhYzLk+YIC9/86o6/ftErswCcKgDWrkAXf8CmsHTZiIiIyGgePoxC//67ERubjLNnh8LKKmNTqqpV+f+9IVj45icxD4EHh4Dg/cDd3Rn9TX8Cao0AVM6SRSMiIiLj27btBkaM2Ifo6GQAwOTJR/DLL20kTpV/sfDNL25tB/b3AYQm6311vwQU1rkeiYiIiEwjJiYZn3++Hxs3XtP1lS7tiI4dK0qYKv9j4Ztf3N+bfdHrVo9FLxERUQFy+nQI+vb1x4MHUbo+X98aWLrUB46OKumCFQAsfPMLITLaTX8EKvQAnMoDFvI3P4aIiIjyjdRUNWbMOIEffzwJjUb7/76DgxLLlvnA17emxOkKBha++YEQwMvbGbcrfQI4cZ0+IiKigiI1VY3mzdcjIOCRrq9p01LYuLEbypRxki5YAcPCN69KjAQCFwOPjwPPrwJJkVInIiIiIhNRKORo3rw0AgIeQS6XYdq05pgwoSnkcgupoxUoLHzzqguzgAu/ZO1XuWh3YyMiIqIC5fvvm+PevZcYN84LDRrw/3pTYOGbV4Wd17/t4QMUbwJU8QUsldJkIiIiIqM4ejQY9+69xNChdXV9CoUc27Z9JGGqgo+Fb14kNMCjoxm3h4UADiWly0NERERGkZKixnffHcGcOQGwtLRAvXruqF27qNSxzAYnjuRFW7z0b9u5S5ODiIiIjObmzedo1GgVZs8OgBBAaqoGK1ZclDqWWeGIb15yZ7d2k4q0xIw+N08uWUZERJSPCSGwYsVFjB9/CImJaQAAhcICP/3UCuPGef3Ho8mYWPjmFTEhwJ5uWfs/OZX7WYiIiMgowsPjMWTIHuzbl7EsaZUqrti8uTvq1CkmYTLzxMI3rwjer3+7VGvgw9WAJXdoISIiyo8OHLiDgQP/QHh4vK5v1Kh6mD27LWxsFBImM18sfPOKa79mtHsdB0p8IF0WIiIiei+pqWp8+eVBXdFbuLAN1qzpgo4dK0qczLzx5La8Ijwwo+1WT7ocRERE9N4UCjk2beoGS0sL+PhUwPXrI1n05gEc8c0r7EoAcY+1bYWNtFmIiIjIIBqNQHR0EpydrXV99esXx9mzQ1C3bjHIZDIJ01E6jvjmBQnhGUWva3VpsxAREZFBnj6NRbt2m9Cx41akpWn07vP0dGfRm4ew8M0LQo5ktEu3kS4HERERGcTf/yZq1lyOw4fvIyDgEX766aTUkegtONUhL3hwMKNdtqN0OYiIiChH4uNTMHbsQfj5Xdb1FStmBy+vEhKmov/CwjcvSI7KaLtUlSwGERER/beLF5/C13cXbt+O0PV161YZfn6d4OLC83TyMha+eYE6JaNtYSVdDiIiInojtVqDWbNOY8qUY7q5vDY2Cixa1A6DB9fhXN58gIVvXpB58wo5C18iIqK8JjVVjbZtN+HYsQe6vvr13bF5c3dUqOAiXTAyCE9uk1r8s4y2zIJLmREREeVBCoUctWq5AQBkMmDSJG+cPj2YRW8+wxFfqf37W0ZbaLTFLxEREeU5P//cGnfvRuLrr5vggw9KSx2H3gELX6k9OprRbjhJuhxERESkc/p0CB4+jEafPjV0fSqVJfbt6yNhKnpfLHylpnLOaJfvIl0OIiIiQmqqGjNmnMCPP56EUilHnTpFUaVKYaljkZHwe3WppcRktJXObz6OiIiITOrevUh4e6/FjBknoNEIJCamYeHCc1LHIiPiiK+UkqKA4APatqUNYOcuaRwiIiJzJITA+vVXMXr0AcTFaZcYlctlmDatOSZMaCptODIqFr5SuusPpMZr29X6c0UHIiKiXBYZmYjhw/dhx44gXV+5cs7YvLk7GjbkLmwFDQtfqQgBnPo243bFntJlISIiMkNHjwajXz9/PHkSq+sbMqQOFixoBzs7rqtfELHwlcql+UB8mLatcgbcG0ubh4iIyIykpKgxePAeXdHr7KyCn18n9OhRVeJkZEo8uU0KcU+Bcz9k3G74HWCplC4PERGRmbGykmPDhq6wsJChZUsPXLs2kkWvGeCIrxQOjwCSXmrbZTsA9cZJm4eIiKiAE0IgLi4F9vYZA03e3qVx/PhANG5cEhYWMgnTUW7hiG9ue3kXuL9X27Z2BdptkDYPERFRARceHo/Onbeha9ft0GiE3n1Nm5Zi0WtGWPjmtienMto1hgHWhaTLQkREVMAdOHAHNWosx759t3HkSDDmzTsjdSSSEKc65LanpzPaZdpKl4OIiKgAS0xMxTff/IXFi8/r+goXtkGVKq4SpiKpsfDNbekjvhaWQNEG0mYhIiIqgK5eDYOv7y78889zXZ+PTwWsWdMZbm52EiYjqbHwzU2JEUDkLW27SF1uWEFERGREGo3AwoVnMWHC30hJUQMAVCpLzJnTBqNG1YdMxrm85o6Fb24Ku5DRdqsrXQ4iIqICJiVFjY4dt+Dw4fu6vlq13LBlSw9UrVpYwmSUl/Dkttz08HBGW8GvWoiIiIzFykqOMmWcdLfHj/fCuXNDWfSSHo745qaQIxntBhOly0FERFQAzZ//Ie7ejcS333qjdeuyUsehPIiFb25RpwAvrmvbrjW4jBkREdF7uHjxKR49ika3blV0fba2VjhyZICEqSivk3yqw7Jly+Dh4QGVSgVPT0+cPHnyrcdv3rwZtWrVgo2NDYoVK4ZBgwYhIiIil9K+I3Uq8PfngNBOtIcLt0QkIiJ6F2q1BjNnnoSX12r0778b9++/lDoS5SOSFr7bt2/Hl19+iUmTJiEwMBDe3t5o3749QkJCsj3+1KlT6N+/P4YMGYJ//vkHv//+Oy5cuIChQ4fmcnIDpMQCuzsB1/0y+qrxt1EiIiJDhYREo2XLDfj22yNIS9MgLi4Fs2ef/u8HEr0iaeE7b948DBkyBEOHDkWVKlWwYMEClCxZEsuXL8/2+LNnz6JMmTIYM2YMPDw80LRpUwwfPhwXL17M5eQG+Gsk8OCgti23Any2AB7tpc1ERESUz2zbdgM1ay7HiRMPAQAyGTBpkjcWLeL/qZRzkhW+KSkpuHTpEtq21d+9rG3btggICMj2MY0bN8bjx4+xf/9+CCHw7Nkz7NixAx06dHjj6yQnJyMmJkbvkqvCAzPaH/0FVOmdu69PRESUj8XEJKN/f3/07r0T0dHJAIBSpRxx/PhA/PBDSygUcokTUn4iWeH74sULqNVquLm56fW7ubkhLCws28c0btwYmzdvRq9evWBlZYWiRYvCyckJixcvfuPrzJw5E46OjrpLyZIljfo+3irhBRARpG07VwBKeOfeaxMREeVzp0+HoFatFdi48Zqur0+fGrh6dQS8vUtLmIzyK8lPbnt9FxUhxBt3VgkKCsKYMWMwZcoUXLp0CX/++SeCg4MxYsSINz7/xIkTER0drbs8evTIqPnf6vbvGe3iH+Te6xIREeVzyclp+OSTnXjwIAoA4OCgxKZN3bB5c3c4OamkDUf5lmTLmbm6ukIul2cZ3Q0PD88yCpxu5syZaNKkCf73v/8BAGrWrAlbW1t4e3vjhx9+QLFixbI8RqlUQqlUGv8N/BeNGrg8P+N2reG5n4GIiCifUiotsXp1Z3z44SY0aVISmzZ119ugguhdSDbia2VlBU9PTxw+fFiv//Dhw2jcuHG2j0lISICFhX5kuVw7t0cIYZqg7ypwMfDyjrbt3hhwqydtHiIiojxMCIHExFS9vrZty+Hgwb44dmwgi14yCkmnOowbNw6rVq3CmjVrcPPmTYwdOxYhISG6qQsTJ05E//79dcd36tQJu3btwvLly3H//n2cPn0aY8aMQYMGDeDu7i7V28jelaUZ7dqjtKefEhERURaRkYno1WsHevbckWUgq23bcrC0lHxmJhUQku7c1qtXL0RERGD69OkIDQ1F9erVsX//fpQurZ2wHhoaqrem78CBAxEbG4slS5Zg/PjxcHJyQsuWLfHLL79I9Ray9+IfIOqutm1dGKjUS9o8REREedTRo8Ho188fT57EAgBWrLiIkSPrS5yKCiqZyHNzBEwrJiYGjo6OiI6OhoODg2le5O/RwJUl2nbzeYDnWNO8DhERUT6VkqLGd98dwZw5AUivRJydVVi9urPeNsRknkxVr0k64lsgpcQBQeu1bUsboNogafMQERHlMbduvUCfPjsRGJhxgnvLlh5Yv74rSpQw0aAUEVj4Gl/AFO02xQBQpQ+gcpI0DhERUV4hhMDKlZcwbtxBJCamAQAUCgvMnNkKY8d6wcKC58OQabHwNbZ7ezLatd68vjAREZE5SU5Ow8cf/469e2/r+qpUccXmzd1Rp07W5UiJTIGnSRqTOgWIC824XaSudFmIiIjyEKXSEvb2GevqjxpVDxcvfsqil3IVR3yN6ckpIC1B267aj0uYERERZbJ0qQ/u3InAlCnN0LFjRanjkBli4WtMp6dktMu0ly4HERGRxK5de4anT2PRrl15XZ+Tkwrnzg2FjANDJBFOdTCW8CvA09PatrUrUKG7pHGIiIikoNEIzJ9/BvXr+6FPn514/DhG734WvSQlFr7G8jQgo13MC7BUvvlYIiKiAkg7wrsJ48YdQkqKGi9fJuGnn05KHYtIh1MdjOXe3ox2zU+ly0FERCSB3btvYejQPYiISNT1jR/vhR9/bClhKiJ9LHyNQZMGPPgz43apFtJlISIiykXx8SkYO/Yg/Pwu6/qKFbPDhg3d0Lp1WQmTEWXFwtcYbu/MaBepAyhspctCRESUSy5efApf3124fTtC19etW2X4+XWCi4uNhMmIssfC1xjCM37LRc3h0uUgIiLKJUlJaejceStCQ+MAADY2Cixa1A6DB9fhCWyUZ/HkNmN4eSejXbq1dDmIiIhyiUpliWXLOgAA6td3x5UrwzFkSF0WvZSnccT3faXGA4+OatuW1oBDaWnzEBERmUhKihpWVnLd7a5dK8Pfvxc6dKgAhUL+lkcS5Q0c8X1f/2wAkqO07Uq9AAv+LkFERAVLdHQS+vXzR9++uyCE0Luva9fKLHop32CV9j5SYoG/R2XcrvuFdFmIiIhM4PTpEPTt648HD6IAAB06XMWAAbUlzUT0rjji+z7u7MpoF6kDFKktWRQiIiJjSk1VY8qUo/jgg3W6otfBQQmVimNmlH/xT+/7eHAoo121n3Q5iIiIjOju3Uj07bsL58490fU1aVISmzZ1R5kyTtIFI3pPLHzfR/pJbVYOQO3PpM1CRET0noQQWLfuCkaPPoD4+FQAgFwuw/ffN8eECU1hackviil/Y+H7rkLPA/Gh2nahyoDcSto8RERE7yEpKQ39+vljx44gXV+5cs7YvLk7GjYsIWEyIuN558L3+fPn+PfffyGTyVCxYkUULlzYmLnytqCNwIEBGbcdPaTLQkREZARKpRypqWrd7SFD6mDBgnaws+PADhUcBn9nER8fj8GDB8Pd3R0ffPABvL294e7ujiFDhiAhIcEUGfMWIYDDnwJ4tZyLfSmgwQRJIxEREb0vmUyGVas6o1q1wtix42OsWtWZRS8VOAYXvuPGjcPx48exZ88eREVFISoqCn/88QeOHz+O8ePHmyJj3nJvD5CWpG1bWAJD7nA1ByIiyndu3XqB48cf6PW5utrg2rWR6NGjqjShiExMJl5fifo/uLq6YseOHWjevLle/9GjR9GzZ088f/7cmPmMLiYmBo6OjoiOjoaDg4NhD35+HdjSCEh7NbLdYiFQd4zxQxIREZmIEAIrV17CuHEHYW+vxLVrI+DmZid1LCI971WvvYXBI74JCQlwc3PL0l+kSJGCP9XhwqyMordiT6DOaGnzEBERGSA8PB5dumzDyJH/h8TENISHx2PGjBNSxyLKNQYXvl5eXpg6dSqSkpJ0fYmJiZg2bRq8vLyMGi5PSQgH7uzMuN1mJSCTSZeHiIjIAAcO3EHNmsuxd+9tXd9nn9XHrFltJExFlLsMXtVh4cKFaNeuHUqUKIFatWpBJpPhypUrUKlUOHjwoCky5g0XZgNpidp2zU8BlZOkcYiIiHIiMTEV33zzFxYvPq/rK1LEFmvWdEaHDhUlTEaU+wye4wtoR3g3bdqEW7duQQiBqlWrwtfXF9bW1qbIaFTvNGckIghYV03bliuBQbcAxzImy0hERGQMV6+Gwdd3F/75J+P8Gx+fClizpjPn9VKeZqo5vgaP+CYkJMDGxgbDhg0zWog879a2jHbVfix6iYgoz0tMTEXbtpsQHh4PAFCpLDFnThuMGlUfMk7VIzNl8BzfIkWKoG/fvjh48CA0Go0pMuUdD/8CFtkBZ2dk9JXrIl0eIiKiHLK2VmD+/A8BALVqueHSpU/x2WcNWPSSWTO48N2wYQOSk5PRrVs3uLu744svvsCFCxdMkU1a9/YBO9oAqfGZOmVA4RqSRSIiInobtVp/QKpPnxrYtKkbzp0biqpVzWiHVaI3MLjw7d69O37//Xc8e/YMM2fOxM2bN9G4cWNUrFgR06dPN0VGaRx9bX3eYl5Ap98Bh9LS5CEiInqD+PgUfPrpXgwdujfLfb6+NaFUGjyzkahAeqeT214XFBQEX19fXLt2DWq1+r8fIKEcTZZOCAeWZ1qruO9lwK1O7gQkIiIywMWLT+Hruwu3b0cAAH777SN8/HE1iVMRvZ88s4FFuqSkJPz222/o2rUr6tati4iICHz11VdGCyapFzcy2k7lWfQSEVGeo1ZrMHPmSXh5rdYVvTY2CiQn5+0BKCIpGfzdx6FDh7B582bs3r0bcrkcH330EQ4ePIhmzZqZIp807v6R0W5cgKZvEBFRgRASEo1+/fxx4sRDXV+9eu7YvLk7KlZ0kTAZUd5mcOHbtWtXdOjQAevXr0eHDh2gUChMkUtaYZlO1iveVLocREREr9m27QZGjNiH6OhkANpNRL/91htTpzaDQiGXOB1R3mZw4RsWFmbUuRZ50stX2zmqCgH2JaTNQkREBO26vMOH78PGjdd0faVKOWLTpm7w9uaJ10Q5kaPCNyYmRq/YjYmJeeOx+b4oFgJIS9C2bYtpf5UmIiKSmFJpiWfPMpbY7NOnBpYu9YGTk0rCVET5S44KX2dnZ4SGhqJIkSJwcnLKdvFrIQRkMlmeX9XhP8WGAGmJ2rZDKWmzEBERvWJhIcO6dV3g7b0W06Y1h69vTakjEeU7OSp8jxw5gkKFCgEAjh49atJAkkuKymjbl5QsBhERmbe7dyMREZGAhg0zptwVK2aPW7c+h6XlOy/KRGTWclT4Zl6xwcPDAyVLlswy6iuEwKNHj4ybTgoiLaNtUQBP3CMiojxNCIF1665g9OgDcHJS4dq1kShUyFp3P4teondn8N8eDw8PPH/+PEt/ZGQkPDw8jBJKUurUjLYFd7ohIqLcExmZiJ49d2Dw4D2Ij0/FkyexmDbtmNSxiAoMgyu79Lm8r4uLi4NKVQAm2GsyF74c8SUiotxx9Ggw+vXzx5Mnsbq+IUPq4McfW0mYiqhgyXHhO27cOACATCbD5MmTYWNjo7tPrVbj3LlzqF27ttED5joWvkRElItSUtT47rsjmDMnAEJo+5ydVfDz64QePapKG46ogMlx4RsYGAhAO+J7/fp1WFlZ6e6zsrJCrVq1CsaWxSx8iYgol9y69QJ9+uxEYGCYrq9lSw+sX98VJUrk8+VBifKgHBe+6as5DBo0CAsXLsz/6/W+SeY5vnIWvkREZBoJCan44IO1eP5cu3a8QmGBmTNbYexYL1hYcA15IlMw+OS2tWvXFtyiF+CILxER5QobGwV+/LElAKBKFVecPz8M48c3ZtFLZEI5GvHt3r071q1bBwcHB3Tv3v2tx+7atcsowSTDwpeIiEzk9RPEhw6tCyGAvn1rwsaG/+cQmVqOCl9HR0fdX1RHR0eTBpIcC18iIjKyxMRUfPPNXxBCYPFiH12/TCbDp596SpiMyLzkqPBdu3Zttu0CSZN5Awuu40tERO/n6tUw+Pruwj//aNfAb9euPDp0qChxKiLzZPAc38TERCQkJOhuP3z4EAsWLMChQ4eMGkwyGu7cRkRE70+jEZg//wwaNFilK3pVKkvdyWxElPsMHtLs0qULunfvjhEjRiAqKgoNGjSAlZUVXrx4gXnz5mHkyJGmyJl7NNy5jYiI3s/Tp7EYOHA3Dh++r+urVcsNW7b0QNWqhSVMRmTeDB7xvXz5Mry9vQEAO3bsQNGiRfHw4UNs2LABixYtMnrAXJd5xJfLmRERkYH8/W+iZs3lekXv+PFeOHduKIteIokZPKSZkJAAe3t7AMChQ4fQvXt3WFhYoFGjRnj48KHRA+Y6dUpGW8YRXyIiypmkpDSMGXMAfn6XdX3u7vZYv74rWrcuK2EyIkpn8Ihv+fLlsXv3bjx69AgHDx5E27ZtAQDh4eEFY31fdXJGW66ULgcREeUrCoUFbt16obvdrVtlXLs2gkUvUR5icOE7ZcoUfPXVVyhTpgwaNGgALy8vANrR3zp16hg9YK7LPOJrycKXiIhyRi63wMaN3VC8uD1WreqEnTt7wsXFRupYRJSJwd/lf/TRR2jatClCQ0NRq1YtXX+rVq3QrVs3o4aThCZT4WthJV0OIiLK0x4+jMLLl0moXbuorq90aSfcuzcGSiWnyhHlRe/0N7No0aIoWrQoHj9+DJlMhuLFi6NBgwbGziaNmJCMNk9uIyKibGzdeh0jR/4fChWyxpUrI+DgkPENIYteorzL4KkOGo0G06dPh6OjI0qXLo1SpUrByckJM2bMgEajMUXG3BXzIKPNdXyJiCiT6Ogk9Ovnjz59diE6OhnBwVGYNu2Y1LGIKIcM/rV00qRJWL16NX7++Wc0adIEQgicPn0a33//PZKSkvDjjz+aImfuUWbaktmhjGQxiIgobzl9OgR9+/rjwYMoXV+fPjUwZUoz6UIRkUEMLnzXr1+PVatWoXPnzrq+WrVqoXjx4hg1alT+L3wTnr9qyAAbrrdIRGTuUlPVmDHjBH788SQ0GgEAcHBQYtkyH/j61pQ4HREZwuDCNzIyEpUrV87SX7lyZURGRhollKQSXxW+qkLcuY2IyMzduxcJX99dOHfuia6vadNS2LixG8qUcZIuGBG9E4Pn+NaqVQtLlizJ0r9kyRK9VR7yrcQI7bW1q7Q5iIhIUvHxKWjUaLWu6JXLZfjhhxY4dmwAi16ifMrgIc1Zs2ahQ4cO+Ouvv+Dl5QWZTIaAgAA8evQI+/fvN0XG3JW+nJmlStocREQkKVtbK3z3nTe+/PIgypVzxpYtPdCgQXGpYxHRezC48G3WrBlu376NZcuW4ebNmxBCoHv37hg1ahTc3d1NkTF3iVcrU8gMHgwnIqJ8TggBmUymuz16dENoNALDhnnCzo5ruxPldwYVvg8fPsShQ4eQmpqK3r17o1q1aqbKJR2NWnstk0ubg4iIck1KihrffXcEFhYy/Pxza12/hYUMY8d6SZiMiIwpx4XviRMn4OPjg4SEBO0DLS2xfv169O7d22ThJMERXyIis3Lz5nP4+u5CYGAYZDLgww/LoUULD6ljEZEJ5Li6mzx5Mlq0aIHHjx8jIiICgwcPxtdff23KbLlPCADapWpY+BIRFWxCCCxffgGenr8iMDAMAGBpaYF7915KnIyITCXHI77Xr1/HiRMndPN4586dCz8/P7x8+RLOzs4mC5irRKad51j4EhEVWOHh8RgyZA/27but66tSxRVbtvRA7dpFJUxGRKaU48I3KioKRYoU0d22tbWFjY0NoqKiCk7hG/c4o805vkREBdKBA3cwcOAfCA+P1/WNGlUPs2e3hY0Nt6onKsgMOrktKCgIYWFhuttCCNy8eROxsbG6vpo18/EuNnFPM9qZR3+JiCjfS0pKw9dfH8bixed1fYUL22DNmi7o2LGihMmIKLcYVPi2atUKQgi9vo4dO0Imk+mWgFGr1UYNmKsyv7diDaTLQURERieXy3D2bMY3ez4+FbBmTWe4udlJmIqIclOOC9/g4GBT5sgjMhf1sjceRURE+Y9CIcfmzd3RuPEafP99M4waVV9vzV4iKvhyXPiWLl3alDnyBsHCl4iooHj6NBbR0UmoUqWwrq9CBRc8ePAFbG25GQWROeLSBXoyFb4cBSAiyrf8/W+iZs3l6NHjNyQkpOrdx6KXyHyx8NXDEV8iovwsPj4Fn366F927/4aIiETcvPkC06cflzoWEeURBp3cVuAJjvgSEeVXFy8+ha/vLty+HaHr69atMv73v8YSpiKivETyEd9ly5bBw8MDKpUKnp6eOHny5FuPT05OxqRJk1C6dGkolUqUK1cOa9asMVIajvgSEeU3arUGM2eehJfXal3Ra2OjwKpVnbBzZ0+4uNhInJCI8op3HvF9/vw5/v33X8hkMlSsWBGFCxf+7we9Zvv27fjyyy+xbNkyNGnSBCtXrkT79u0RFBSEUqVKZfuYnj174tmzZ1i9ejXKly+P8PBwpKWlvevb0McRXyKifCUkJBr9+vnjxImHur769d2xeXN3VKjgImEyIsqLDC584+PjMXr0aGzcuFG3Zq9cLkf//v2xePFi2Njk/DfrefPmYciQIRg6dCgAYMGCBTh48CCWL1+OmTNnZjn+zz//xPHjx3H//n0UKlQIAFCmTBlD30IOsfAlIsrLYmOTUa/er3j+PAGAdrzi22+9MXVqMygU3H2TiLIyeKrDuHHjcPz4cezZswdRUVGIiorCH3/8gePHj2P8+PE5fp6UlBRcunQJbdu21etv27YtAgICsn3Mnj17UK9ePcyaNQvFixdHxYoV8dVXXyExMfGNr5OcnIyYmBi9y5uJt9xHRER5ib29El9+2QgAUKqUI44fH4gffmjJopeI3sjgEd+dO3dix44daN68ua7Px8cH1tbW6NmzJ5YvX56j53nx4gXUajXc3Nz0+t3c3PS2Rc7s/v37OHXqFFQqFfz9/fHixQuMGjUKkZGRb5znO3PmTEybNi1nb45THYiI8pVvvmkCjUbg888bwMlJJXUcIsrjDB7xTUhIyFKsAkCRIkWQkJBgcIDXd81J3/o4OxqNBjKZDJs3b0aDBg3g4+ODefPmYd26dW8c9Z04cSKio6N1l0ePHr0lDU9uIyLKi9LSNJg69ShmzNBfmkwut8B3333AopeIcsTgEV8vLy9MnToVGzZsgEql/YcmMTER06ZNg5eXV46fx9XVFXK5PMvobnh4eLaFNQAUK1YMxYsXh6Ojo66vSpUqEELg8ePHqFChQpbHKJVKKJXKnIXiiC8RUZ5z714kfH134dy5J7CwkKF167Lw8iopdSwiyocMHvFdsGABAgICUKJECbRq1QqtW7dGyZIlERAQgIULF+b4eaysrODp6YnDhw/r9R8+fBiNG2e/5mKTJk3w9OlTxMXF6fpu374NCwsLlChRwtC3kg2O+BIR5RVCCKxbdwW1a6/EuXNPAGjHJK5efSZxMiLKrwwe8a1Rowbu3LmDTZs24datWxBC4JNPPoGvry+sra0Neq5x48ahX79+qFevHry8vPDrr78iJCQEI0aMAKCdpvDkyRNs2LABANCnTx/MmDEDgwYNwrRp0/DixQv873//w+DBgw1+7eyx8CUiygsiIxMxfPg+7NgRpOsrV84Zmzd3R8OGxhjoICJzZFDhm5qaikqVKmHfvn0YNmzYe794r169EBERgenTpyM0NBTVq1fH/v37Ubp0aQBAaGgoQkJCdMfb2dnh8OHDGD16NOrVqwcXFxf07NkTP/zww3tnAcCpDkREecDRo8Ho188fT57E6vqGDKmDBQvawc7OSsJkRJTfGVT4KhQKJCcnv/Hks3cxatQojBo1Ktv71q1bl6WvcuXKWaZHGA9HfImIpJKSosbkyUcwe3aAbhzC2VkFP79O6NGjqrThiKhAMHiO7+jRo/HLL78Yb7e0vCQtOaPNEV8iolyl0QgcOHBXV/S2bOmBa9dGsuglIqMxeI7vuXPn8Pfff+PQoUOoUaMGbG1t9e7ftWuX0cLlutSMk+Zgyb3diYhyk0pliS1beqBJkzWYMuUDjB3rBQsLDkIQkfEYXPg6OTmhR48epsgiPU2mUWwrO+lyEBGZgfDweMTGJqNcuUK6vurVi+Dhwy+5Li8RmYTBhe/atWtNkSNvEOqMtoxbXhIRmcqBA3cwcOAfcHe3x9mzQ6BUZvx3xKKXiEzF4Dm+BVpydEbbwuDfCYiI6D8kJqZizJgD8PHZgvDweFy5EoYffzwpdSwiMhM5qu7q1q2Lv//+G87OzqhTp85bV3W4fPmy0cLlurDzGe3MS5sREdF7u3o1DL6+u/DPP891fT4+FfDZZ/UlTEVE5iRHhW+XLl102/527drVlHmkFXkro61ykiwGEVFBotEILFx4FhMm/I2UFO2UMpXKEnPmtMGoUfWNukQmEdHbyIQwr6HNmJgYODo6Ijo6Gg4ODvp3rnAH4kO17X5XgCK1cj0fEVFB8vRpLAYM2I2//rqv66tVyw1btvRA1aqFJUxGRHnZW+u19/BOc3yjoqKwatUqTJw4EZGRkQC0UxyePHlitGCScPTIaNtzS0wiovcRHZ2E2rVX6BW948d74dy5oSx6iUgSBhe+165dQ8WKFfHLL79gzpw5iIqKAgD4+/tj4sSJxs6XyzJ93aZ0kiwFEVFB4OiowqefegIA3N3tcfhwP8yZ01ZvBQciotxkcOE7btw4DBw4EHfu3IFKlbHkTPv27XHixAmjhst1ItM6vjIueEFE9L6mTm2GiROb4tq1EWjduqzUcYjIzBn8a/eFCxewcuXKLP3FixdHWFiYUUJJRp2ivbaw5JbFREQGUKs1mDXrNFQqS4wd66XrVyjk+OmnVhImIyLKYHDhq1KpEBMTk6X/33//ReHC+XzOVnig9lqulDYHEVE+EhISjX79/HHixEMoFBZo3rwM6tQpJnUsIqIsDP4+v0uXLpg+fTpSU1MBADKZDCEhIZgwYUL+3so4fbQXAFLjpctBRJSPbNt2AzVrLseJEw8BAGlpGgQEPJI4FRFR9gwufOfMmYPnz5+jSJEiSExMRLNmzVC+fHnY29vjxx9/NEXG3JESm9F2qSZdDiKifCAmJhn9+/ujd++diI5OBgCUKuWI48cH4rPPGkicjogoewZPdXBwcMCpU6dw5MgRXL58GRqNBnXr1kXr1q1NkS/3JDzLaKclSpeDiCiPO306BH37+uPBgyhdX58+NbB0qQ+cnFRvfiARkcTeeU2Zli1bomXLlsbMIq24pxlt98bS5SAiyqNSU9WYMeMEfvzxJDQa7d5HDg5KLFvmA1/fmhKnIyL6bzkqfBctWpTjJxwzZsw7h5HUyzsZ7cL8B5yI6HUpKWps3/6Pruht2rQUNm7shjJlnKQNRkSUQzkqfOfPn693+/nz50hISICTkxMA7U5uNjY2KFKkSP4tfNMSMtoOpaXLQUSUR9naWmHz5u744IO1mDTJGxMmNIVczjXPiSj/yFHhGxwcrGtv2bIFy5Ytw+rVq1GpUiUA2qXMhg0bhuHDh5smZW5IjMhoW9pIl4OIKI+IjExEfHwKSpZ01PXVq+eOBw++RJEithImIyJ6Nwb/qj558mQsXrxYV/QCQKVKlTB//nx89913Rg2Xq9TJGW2Vs3Q5iIjygKNHg1Gz5nL07LkDaWkavftY9BJRfmVw4RsaGqpbwzcztVqNZ8+eZfOIfEKTabtiC+4jT0TmKSVFja+/PoxWrTbgyZNYnD37GL/8ckrqWERERmFw4duqVSsMGzYMFy9ehBDaExwuXryI4cOH5+8lzYQ6o83Cl4jM0M2bz9Go0SrMnh2AV/+8o2VLDwwYUFvSXERExmJw4btmzRoUL14cDRo0gEqlglKpRMOGDVGsWDGsWrXKFBlzx5OTGW2ZXLocRES5TAiBFSsuwtPzVwQGhgEAFAoLzJ7dBocP90OJEg4SJyQiMg6DhzYLFy6M/fv34/bt27h16xaEEKhSpQoqVqxoiny5x6YogGvattxK0ihERLklPDweQ4fuwd69t3V9Vaq4YvPm7qhTp5iEyYiIjO+dv9OvWLFi/i92M7PMtNuQykW6HEREuSQqKgm1aq1AWFicrm/UqHqYPbstbGwUEiYjIjKNdyp8Hz9+jD179iAkJAQpKSl6982bN88owXKd3slt/AefiAo+JycVPvmkGhYsOIfChW2wZk0XdOxYgAY0iIheY3Dh+/fff6Nz587w8PDAv//+i+rVq+PBgwcQQqBu3bqmyJg7NJlWquDJbURkJmbObA2NRuDbb73h5mYndRwiIpMy+OS2iRMnYvz48bhx4wZUKhV27tyJR48eoVmzZvj4449NkTF3xIdqr2VyQMENLIioYNFoBObPP4Nff72k169SWWLhwvYseonILBg8tHnz5k1s3bpV+2BLSyQmJsLOzg7Tp09Hly5dMHLkSKOHzBUvbmivrew54ktEBcrTp7EYOHA3Dh++D5XKEt7epVClSmGpYxER5TqDR3xtbW2RnKzd5czd3R337t3T3ffixQvjJcttVvba6+QoSWMQERmTv/9N1Ky5HIcP3wcAJCWl6dpERObG4KHNRo0a4fTp06hatSo6dOiA8ePH4/r169i1axcaNWpkioy5IyVWe+1aXdocRERGEB+fgrFjD8LP77Kuz93dHuvXd0Xr1mUlTEZEJB2DC9958+YhLk679M3333+PuLg4bN++HeXLl8f8+fONHjBXqDOtTGFpLV0OIiIjuHjxKXx9d+H27QhdX7duleHn1wkuLjyHgYjMl8GFb9myGSMFNjY2WLZsmVEDSSI5OqOdmI+naxCRWVOrNZg16zSmTDmGtDQNAMDGRoFFi9ph8OA6kMlkEickIpIWz+IC9Ed8i9SRLgcR0XuIj0/FypWXdEVv/fru2Ly5OypU4KY8RERADgtfZ2fnHI8UREZGvlcgSSQ8y2hr1NLlICJ6Dw4OSmzc2A2tWm3A1183wdSpzaBQyKWORUSUZ+So8F2wYIGuHRERgR9++AEffvghvLy8AABnzpzBwYMHMXnyZJOENLnMu7YlhEmXg4jIADExyUhISEXRohlr8Hp7l8a9e2NQsqSjhMmIiPImmRBCGPKAHj16oEWLFvj888/1+pcsWYK//voLu3fvNmY+o4uJiYGjoyOio6Ph4OCg7XwSAGxrom17jgWa59Ntl4nIbJw+HYK+ff3h4eGEv/7qDwsLzt8looIj23rNCAxex/fgwYNo165dlv4PP/wQf/31l1FC5TqRaXqDjNOeiSjvSk1VY8qUo/jgg3V48CAKR48+wPz5Z6SORUSULxhc+Lq4uMDf3z9L/+7du+Hikk9PoIgNyWhbcD4cEeVNd+9Gwtt7LWbMOAGNRvtlXdOmpdCjR1WJkxER5Q8GD29OmzYNQ4YMwbFjx3RzfM+ePYs///wTq1atMnrAXBF5K6PN5cyIKI8RQmDduisYPfoA4uNTAQByuQzTpjXHhAlNIZcbPIZBRGSWDC58Bw4ciCpVqmDRokXYtWsXhBCoWrUqTp8+jYYNG5oio+nJVRntQlWky0FE9JrIyEQMH74PO3YE6frKlXPGli090KBBcQmTERHlPwYVvqmpqfj0008xefJkbN682VSZcp/QZLSdK0qXg4gok5cvE1Gr1go8fhyj6xsypA4WLGgHOzsrCZMREeVPBn0/plAosp3fm+9pMm1gIed/JkSUNzg7W8PHp/yrtgo7dnyMVas6s+glInpHBk8M69atW55fssxg137NaFvZS5eDiOg18+Z9iCFD6uDatZE8iY2I6D0ZPMe3fPnymDFjBgICAuDp6QlbW1u9+8eMGWO0cLnGpRqQEK5tc44vEUlACIGVKy/Bzs4KffvW1PXb2lph1arOEiYjIio4DN7AwsPD481PJpPh/v377x3KlLJdEHlLIyD0nLY9Tg3IeIY0EeWe8PB4DB26B3v33oadnRWuXBmOcuUKSR2LiEgyptrAwuAR3+DgYKO9eJ6RGKG9Vjqx6CWiXHXgwB0MGvQHnj2LBwDExaVg377b+OKLRhInIyIqeN65yktJScG///6LtLQ0Y+aRRnyY9lrJve2JKHckJqZizJgD8PHZoit6Cxe2wd69vVn0EhGZiMGFb0JCAoYMGQIbGxtUq1YNISHaXc/GjBmDn3/+2egBTU6TBqTGaduqfLrzHBHlK9euPUP9+n5YvPi8rs/HpwKuXx+Jjh25pCIRkakYXPhOnDgRV69exbFjx6BSZWz80Lp1a2zfvt2o4XJFSmxGW8U5dURkOhqNwPz5Z1C/vh/++ec5AEClssSSJe2xb19vuLnZSZyQiKhgM3iO7+7du7F9+3Y0atQIMplM11+1alXcu3fPqOFyRezjjLZ9CelyEFGBFx2dhNmzA5CSogYA1Kzphi1buqNatSISJyMiMg8Gj/g+f/4cRYpk/Uc6Pj5erxDON9RJGW0FR1uIyHScna2xfn1XWFjIMH68F86fH8qil4goFxlc+NavXx//93//p7udXuz6+fnBy8vLeMlyi5q7thGRacTHpyAiIkGvr02bcvj3388xZ05bKJUGf+lGRETvweB/dWfOnIl27dohKCgIaWlpWLhwIf755x+cOXMGx48fN0VG00qNz2hbqt58HBGRAS5efApf310oX74Q9u3rrfeNWPnyPJ+AiEgKOR7xvXLlCgCgcePGOH36NBISElCuXDkcOnQIbm5uOHPmDDw9PU2V03RiHmS07UtKFoOICga1WoOZM0/Cy2s1bt+OwP79d7B8+UWpYxEREQwY8a1bty7q1KmDoUOHok+fPli/fr0pc+WeqEw7zTmWlS4HEeV7ISHR6NfPHydOPNT11a/vjjZt+G8LEVFekOMR39OnT6Nu3bqYMGECihUrhn79+uHo0aOmzJY7ojPtROf45u2YiYjeZtu2G6hZc7mu6LWwkGHSJG+cPj0YFSpwjXAiorwgx4Wvl5cX/Pz8EBYWhuXLl+PRo0do3bo1ypUrhx9//BGPHz/+7yfJi6LTR3xlgENpSaMQUf4TE5OM/v390bv3TkRHJwMASpVyxLFjA/DDDy2hUMglTkhEROkMXtXB2toaAwYMwLFjx3D79m307t0bK1euhIeHB3x8fEyR0bTSR3ztS3BVByIySEREAmrXXoGNG6/p+vr0qYGrV0fA25u/SBMR5TUGF76ZlStXDhMmTMCkSZPg4OCAgwcPGitX7hACSH6pbdu4SZuFiPIdFxcbNGlSCgDg4KDEpk3dsHlzdzg5cYUYIqK86J0XkTx+/DjWrFmDnTt3Qi6Xo2fPnhgyZIgxs5meJg0QGm3b0lraLESULy1Z0h5qtQY//dQKZco4SR2HiIjewqDC99GjR1i3bh3WrVuH4OBgNG7cGIsXL0bPnj1ha2trqoymk3nXNq7hS0RvIYTA+vVX4eCgRPfuVXT9jo4qbNnSQ8JkRESUUzkufNu0aYOjR4+icOHC6N+/PwYPHoxKlSqZMpvppWUqfOUsfIkoe5GRiRg+fB927AiCk5MK9eu7o2RJR6ljERGRgXJc+FpbW2Pnzp3o2LEj5PICcpZyGkd8iejtjh4NRr9+/njyJBYAEBWVhB07gjB2bD7cop2IyMzluPDds2ePKXNIg1MdiOgNUlLU+O67I5gzJwBCaPucnVXw8+uEHj2qShuOiIjeyTuf3FYgcKoDEWXj1q0X6NNnJwIDw3R9LVt6YP36rihRwkHCZERE9D7Mu/DliC8RZSKEwMqVlzBu3EEkJqYBABQKC8yc2Qpjx3rBwkImcUIiInof5l34csSXiDKJjEzE5MlHdUVvlSqu2LKlB2rXLipxMiIiMob32sAi3+PJbUSUiYuLDVat6gQAGDWqHi5e/JRFLxFRAfJOhe/GjRvRpEkTuLu74+HDhwCABQsW4I8//jBqOJPjVAcis5aYmIro6CS9vi5dKuPatRFYurQDbGwUEiUjIiJTMLjwXb58OcaNGwcfHx9ERUVBrVYDAJycnLBgwQJj5zMtTnUgMlvXrj1D/fp+GDp0L0T6sg2v1KjBLcyJiAoigwvfxYsXw8/PD5MmTdJbz7devXq4fv26UcOZHEd8icyORiMwf/4Z1K/vh3/+eY4dO4Kwfv1VqWMREVEuMPjktuDgYNSpUydLv1KpRHx8vFFC5RqO+BKZladPYzFw4G4cPnxf11erlhsaNCguYSoiIsotBo/4enh44MqVK1n6Dxw4gKpV89mi7nontymly0FEJufvfxM1ay7XK3rHj/fCuXNDUbVqYQmTERFRbjF4xPd///sfPvvsMyQlJUEIgfPnz2Pr1q2YOXMmVq1aZYqMppOWkNG2tJEuBxGZTHx8CsaOPQg/v8u6Pnd3e6xf3xWtW5eVMBkREeU2gwvfQYMGIS0tDV9//TUSEhLQp08fFC9eHAsXLsQnn3xiioymkxqX0VbYSpeDiEzi+fN4NG26FrdvR+j6unWrDD+/TnBx4S+7RETm5p2WMxs2bBgePnyI8PBwhIWF4dGjRxgyZMg7BVi2bBk8PDygUqng6emJkydP5uhxp0+fhqWlJWrXrv1OrwsASI7OaCsd3/15iChPcnW1QbVq2mkMNjYKrFrVCTt39mTRS0Rkpt5r5zZXV9f3evHt27fjyy+/xLJly9CkSROsXLkS7du3R1BQEEqVKvXGx0VHR6N///5o1aoVnj179u4BEsIz2gq7d38eIsqTZDIZ/Pw6Qa0WmDOnDSpUcJE6EhERSUgmXl/AMht16tSBTJazPeovX7783we90rBhQ9StWxfLly/X9VWpUgVdu3bFzJkz3/i4Tz75BBUqVIBcLsfu3buzPdnuTWJiYuDo6Ijo6Gg47O8APDmlvWN0LGDF4pcoP9u27QYcHZVo376C1FGIiOg96NVrDg5Ge94cjfh27dpV105KSsKyZctQtWpVeHl5AQDOnj2Lf/75B6NGjcrxC6ekpODSpUuYMGGCXn/btm0REBDwxsetXbsW9+7dw6ZNm/DDDz/85+skJycjOTlZdzsmJib7A7mOL1G+FROTjM8/34+NG6+hcGEbXL8+Em5u/EWWiIj05ajwnTp1qq49dOhQjBkzBjNmzMhyzKNHj3L8wi9evIBarYabm/4OSW5ubggLC8v2MXfu3MGECRNw8uRJWFrmbJbGzJkzMW3atBznIqL85fTpEPTt648HD6IAAM+fJ2Dz5usYN85L2mBERJTnGHxy2++//47+/ftn6e/bty927txpcIDXp1AIIbKdVqFWq9GnTx9MmzYNFStWzPHzT5w4EdHR0bqLIcU5EeVdqalqTJlyFB98sE5X9Do4KLFpUzcWvURElC2DT26ztrbGqVOnUKGC/hy6U6dOQaXK+XQBV1dXyOXyLKO74eHhWUaBASA2NhYXL15EYGAgPv/8cwCARqOBEAKWlpY4dOgQWrZsmeVxSqUSSiU3pyAqSO7ejUTfvrtw7twTXV/TpqWwcWM3lCnjJF0wIiLK0wwufL/88kuMHDkSly5dQqNGjQBo5/iuWbMGU6ZMyfHzWFlZwdPTE4cPH0a3bt10/YcPH0aXLl2yHO/g4IDr16/r9S1btgxHjhzBjh074OHhYehbIaJ8RgiBdeuuYPToA4iPTwUAyOUyTJvWHBMmNIVc/k4rNBIRkZkwuPCdMGECypYti4ULF2LLli0AtCsxrFu3Dj179jToucaNG4d+/fqhXr168PLywq+//oqQkBCMGDECgHaawpMnT7BhwwZYWFigevXqeo8vUqQIVCpVln4iKpieP0/A2LEHdUVvuXLO2Ly5Oxo2LCFxMiIiyg/eaR3fnj17GlzkZqdXr16IiIjA9OnTERoaiurVq2P//v0oXbo0ACA0NBQhISHv/TpEVDAUKWKLFSs6onfvnRgypA4WLGgHOzsrqWMREVE+kaN1fAuSN67jOzYVsHiv/TyIyMhSUtRITVXD1la/uD1//gkaNCguUSoiIjI1U63jywlxRJQn3br1Al5eq/HZZ/uz3Meil4iI3gULXyLKU4QQWLHiIurWXYnLl0Oxfv1V/PbbP1LHIiKiAoDf7RNRnvH8eTyGDNmDvXtv6/qqVHFFhQqFJExFREQFBQtfIsoT/vzzLgYO3I1nz+J1faNG1cPs2W1hY6OQMBkRERUU71T4Pn78GHv27EFISAhSUlL07ps3b55RghGReUhMTMWECX9h0aLzur7ChW2wZk0XdOyY810aiYiI/ovBhe/ff/+Nzp07w8PDA//++y+qV6+OBw8eQAiBunXrmiIjERVQ4eHxaNVqA27cCNf1+fhUwJo1neHmZidhMiIiKogMPrlt4sSJGD9+PG7cuAGVSoWdO3fi0aNHaNasGT7++GNTZCSiAsrV1QbFi9sDAFQqSyxZ0h779vVm0UtERCZhcOF78+ZNDBgwAABgaWmJxMRE2NnZYfr06fjll1+MHtCkUmK01zI5IOMCF0S5zcJChrVru6B167K4dOlTfPZZA8hkMqljERFRAWVwtWdra4vk5GQAgLu7O+7du6e778WLF8ZLZmpCA0T+q207V2DhS5QLdu++hWPHHuj1FStmj8OH+6Fq1cLShCIiIrNh8BzfRo0a4fTp06hatSo6dOiA8ePH4/r169i1axcaNWpkioymkZYEqLUFPGyLSZuFqICLj0/B2LEH4ed3GcWL2+PatZEoVMha6lhERGRmDC58582bh7i4OADA999/j7i4OGzfvh3ly5fH/PnzjR7QZNKLXgCQK6XLQVTAXbz4FL6+u3D7dgQA4MmTWKxbdwXjxnlJnIyIiMyNwYVv2bJldW0bGxssW7bMqIFyjTo1oy23ki4HUQGlVmswa9ZpTJlyDGlpGgCAjY0Cixa1w+DBdSROR0RE5sjgia1//fXXG+9buXLle4XJVepM6w9zxJfIqEJCotGy5QZ8++0RXdFbr547AgOHY8iQujyBjYiIJGFw4Zs+rzfzxhXPnz9Hp06dMHHiRKOGMylN5sKXI75ExrJt2w3UrLkcJ048BADIZMCkSd4ICBiMihVdJE5HRETmzODC98SJE9i7dy/q16+Pf/75B//3f/+H6tWrIy4uDlevXjVFRtPIXPhasPAlMoawsDgMHboH0dHaOfSlSjni+PGB+OGHllAo5BKnIyIic2dw4duwYUMEBgaiZs2a8PT0RLdu3TB+/HgcOXIEJUuWNEVG01BzxJfI2IoWtcPChe0AAL17V8fVqyPg7V1a4lRERERaBp/cBgD//vsvLly4gBIlSuDp06e4desWEhISYGtra+x8psPCl+i9paaqoVYLqFQZ/5QMHlwHZcs6o0ULDwmTERERZWXwiO/PP/8MLy8vtGnTBjdu3MCFCxd0I8BnzpwxRUbTyLyqA6c6EBns7t1IeHuvxfjxB/X6ZTIZi14iIsqTDC58Fy5ciN27d2Px4sVQqVSoVq0azp8/j+7du6N58+YmiGgimszLmSmky0GUzwghsHZtIGrXXoFz555g2bKL2LfvttSxiIiI/pPBUx2uX78OV1dXvT6FQoHZs2ejY8eORgtmcpkLXwsWvkQ5ERmZiOHD92HHjiBdX7lyzihSJB9NcyIiIrNlcOH7etGbWbNmzd4rTK6Ke5rRVthJl4Monzh6NBj9+vnjyZNYXd+QIXWwYEE72NlxuhAREeV973Ry24ULF/D7778jJCREbz1fANi1a5dRgplcQmhGu1Al6XIQ5XEpKWp8990RzJkTACG0fc7OKvj5dUKPHlWlDUdERGQAg+f4btu2DU2aNEFQUBD8/f2RmpqKoKAgHDlyBI6OjqbIaHoW71T/ExV44eHxaNRoFWbPzih6W7XywPXrI1n0EhFRvmNw4fvTTz9h/vz52LdvH6ysrLBw4ULcvHkTPXv2RKlSpUyRkYgk4uJiDXt77ZbeCoUF5sxpg0OH+qF4cQeJkxERERnO4ML33r176NChAwBAqVQiPj4eMpkMY8eOxa+//mr0gEQkHbncAhs3dkPjxiVx/vwwjB/fGBYWMqljERERvRODC99ChQohNlZ7ckvx4sVx48YNAEBUVBQSEhKMm46IctWBA3dw9uxjvb5SpRxx6tQg1K5dVKJURERExpHjwnfw4MGIjY2Ft7c3Dh8+DADo2bMnvvjiCwwbNgy9e/dGq1atTBaUiEwnMTEVY8YcgI/PFvTpsxMxMcl698tkHOUlIqL8L8eF7/r165GYmIglS5bgk08+AQBMnDgRX331FZ49e4bu3btj9erVJgtKRKZx9WoY6tf3w+LF5wEAwcFRWL36ssSpiIiIjC/HyxmIV6d0FypUSNdnYWGBr7/+Gl9//bXxkxGRSWk0AgsXnsWECX8jJUUNAFCpLDF3bluMHFlP4nRERETGZ9A6Xvy6k6hgePo0FgMH7sbhw/d1fbVquWHLlh6oWrWwhMmIiIhMx6DCt2LFiv9Z/EZGRr5XICIyLX//mxg2bC8iIhJ1fePHe+HHH1tCqeSa1kREVHAZ9L/ctGnT8u8mFUSEp09j0bv3TiQna6c2uLvbY/36rmjduqzEyYiIiEzPoML3k08+QZEiRUyVhYhMzN3dHrNnt8GYMX+iW7fK8PPrBBcXG6ljERER5YocF76c30uU/6jVGmg0AgqFXNf3+ecNULasM3x8KvDvNRERmZUcL2eWvqoDEeUPISHRaNlyAyZNOqLXL5PJ0KHDf8/XJyIiKmhyPOKr0WhMmYOIjGjbthsYMWIfoqOTceLEQ3z4YTm0asV5vEREZN54CjdRARITk4zPP9+PjRuv6fpKlXKESsW/6kREROb7v2Fapi1ZLayky0FkJKdPh6BvX388eBCl6+vTpwaWLvWBk5NKumBERER5hPkWvskxGW2Vk2QxiN5XaqoaM2acwI8/noRGo52L7+CgxLJlPvD1rSlxOiIiorzDfAvflKiMthXXJqb8KTw8Hp07b8W5c090fU2blsLGjd1QpoyTdMGIiIjyoByv6lDgcMSXCgBnZxXSF1yRy2X44YcWOHZsAIteIiKibJhx4Rud0eaIL+VTCoUcmzd3R+3aRREQMASTJn0Audx8/1oTERG9jflOdUh9NeIrVwKWSmmzEOXQ0aPBcHa2Ru3aRXV95csXwuXLn3JdXiIiov9gvkNDSa9GfJVOksYgyomUFDW+/vowWrXagN69dyIhIVXvfha9RERE/818C9+UVyO+Sk5zoLzt1q0XaNRoFWbPDoAQ2tt+fpekjkVERJTvsPDliC/lUUIIrFhxEXXrrkRgYBgAQKGwwJw5bTB6dEOJ0xEREeU/5jvHNx1HfCkPCg+Px9Che7B3721dX5UqrtiypYfe/F4iIiLKORa+HPGlPObAgTsYNOgPPHsWr+sbNaoeZs9uCxsbhYTJiIiI8jcWvhzxpTzk8eMYdOmyDampGgBA4cI2WLOmCzp2rChxMiIiovzPfOf4puOIL+UhJUo4YPr0FgCA9u3L4/r1kSx6iYiIjIQjvhzxJQlpNAJCCL1NJ/73v8YoV84ZH31UlcuUERERGRFHfDniSxJ5+jQW7dptwowZJ/T65XILfPxxNRa9RERERsYRX474kgT8/W9i2LC9iIhIxN9/B6Nt23Jo3Lik1LGIiIgKNBa+HPGlXBQfn4KxYw/Cz++yrs/NzRapqWoJUxEREZkHFr42blInIDNx8eJT+Pruwu3bEbq+bt0qw8+vE1xcbCRMRkREZB5Y+Nqy8CXTUqs1mDXrNKZMOYa0NO0yZTY2Cixa1A6DB9fhXF4iIqJcwsKXI75kQuHh8fj4499x4sRDXV/9+u7YvLk7KlRwkTAZERGR+THvVR2UToClSuoUVIA5OCgRFZUEAJDJgEmTvHH69GAWvURERBIw78KXo71kYiqVJbZs6Y5KlVxw/PhA/PBDSygUcqljERERmSXznupgW1TqBFTAnD4dAmdna1StWljXV61aEfzzzyi9TSqIiIgo95n3/8Q2RaROQAVEaqoaU6YcxQcfrEOfPjuRnJymdz+LXiIiIumZ9//GCjupE1ABcO9eJLy912LGjBPQaASuXn2GX3+9JHUsIiIieo15T3XgiW30HoQQWL/+KkaPPoC4uBQAgFwuw7RpzTFqVH1pwxEREVEWLHyJ3kFkZCKGD9+HHTuCdH3lyjljy5YeaNCguITJiIiI6E3Mu/CVs/Alwx05Eoz+/f3x5Emsrm/IkDpYsKAd7OysJExGREREb2PehS9HfMlAISHR+PDDTbod2JydVfDz64QePapKnIyIiIj+i3mf3MYRXzJQqVKOmDixKQCgZUsPXLs2kkUvERFRPsERX6K3EEJACMDCQqbrmzz5A5Qr54x+/Wrp9RMREVHeZt4jvix86S3Cw+PRpcs2zJ0boNevUMgxYEBtFr1ERET5jHmP+MrM++3Tmx04cAeDBv2BZ8/i8eefd9GqVVnUrVtM6lhERET0Hsy78pNxxI70JSam4ptv/sLixed1fU5OKrx8mShhKiIiIjIG8y58wcKXMly9GgZf313455/nur727ctj7doucHPjLn9ERET5nXkXvhzxJQAajcDChWcxYcLfSElRAwBUKkvMnt0Gn31WHzL+OSEiIioQzLvwJbP3/Hk8+vTZhb/+uq/rq1nTDVu2dEe1akUkTEZERETGZt6rOnCqg9mzsVEgJCRad3v8eC+cPz+URS8REVEBZN6FL7/CNnu2tlbYsqU7ypRxwuHD/TBnTlsolfwihIiIqCAy8//hWfiam4sXn8LZWYVy5Qrp+jw93XH79udQKOQSJiMiIiJTk3zEd9myZfDw8IBKpYKnpydOnjz5xmN37dqFNm3aoHDhwnBwcICXlxcOHjz47i/OEV+zoVZrMHPmSXh5rYav7y6kpqr17mfRS0REVPBJWvhu374dX375JSZNmoTAwEB4e3ujffv2CAkJyfb4EydOoE2bNti/fz8uXbqEFi1aoFOnTggMDMzl5JSfhIREo2XLDfj22yNIS9Pg3LknWLXqstSxiIiIKJfJhBBCqhdv2LAh6tati+XLl+v6qlSpgq5du2LmzJk5eo5q1aqhV69emDJlSo6Oj4mJgaOjI6J/ABy6bwaq9Hmn7JQ/bNt2AyNG7EN0dDIA7SD/t996Y+rUZhzlJSIiyqN09Vp0NBwcHIz2vJLN8U1JScGlS5cwYcIEvf62bdsiICAgR8+h0WgQGxuLQoUKvfGY5ORkJCcn627HxMRkupdTHQqqmJhkfP75fmzceE3XV6qUIzZt6gZv79ISJiMiIiKpSDbV4cWLF1Cr1XBzc9Prd3NzQ1hYWI6eY+7cuYiPj0fPnj3feMzMmTPh6Oiou5QsWTLjTs7xLZACAh6hdu0VekVvnz41cPXqCBa9REREZkzyk9te3xVLCJGjnbK2bt2K77//Htu3b0eRIm9ec3XixImIjo7WXR49evTemSnvevAgCs2arUNwcBQAwMFBiU2bumHz5u5wclJJG46IiIgkJVnh6+rqCrlcnmV0Nzw8PMso8Ou2b9+OIUOG4LfffkPr1q3feqxSqYSDg4PeJQNHfAuaMmWcMHp0AwBAkyYlcfXqCPj61pQ4FREREeUFkhW+VlZW8PT0xOHDh/X6Dx8+jMaNG7/xcVu3bsXAgQOxZcsWdOjQ4f1CcKpDvieEwOvnZ/70UyssXeqDY8cGokwZJ2mCERERUZ4j6VSHcePGYdWqVVizZg1u3ryJsWPHIiQkBCNGjACgnabQv39/3fFbt25F//79MXfuXDRq1AhhYWEICwtDdHT0m17iP7Dwzc8iIxPRs+cOLFt2Qa9fpbLEqFH1YWkp+UweIiIiykMk3bmtV69eiIiIwPTp0xEaGorq1atj//79KF1aewJSaGio3pq+K1euRFpaGj777DN89tlnuv4BAwZg3bp1uR2fJHT0aDD69fPHkyex2LfvNpo3L4Nq1d4815uIiIhI0nV8paC3ju/HvwMVP5I6EhkgJUWN7747gjlzApD+J9fZWYVt2z5C27blpA1HRERERlHg1vHNGzjVIT+5efM5fH13ITAw44TIli09sH59V5QoYby/FERERFQwmXfhy5Pb8gUhBFasuIjx4w8hMTENAKBQWGDmzFYYO9YLFhb8ORIREdF/M+/Cl/K8iIgEDBz4B/btu63rq1LFFZs3d0edOsUkTEZERET5jXmf9i5j3Z/XWVpa4Pr1Z7rbo0bVw8WLn7LoJSIiIoOZd+GrcpY6Af0HR0cVNm3qjmLF7LB3b28sXdoBNjYKqWMRERFRPmTeQ56qQlInoNdcvRqGQoWsUbKko66vadNSuH//C6hU5v3HlYiIiN6PmY/4svDNKzQagfnzz6BBg1Xo188farVG734WvURERPS+WPiS5J4+jUW7dpswbtwhpKSocfz4Q6xZEyh1LCIiIipgzHcYTWEDWCqlTmH2/P1vYtiwvYiISNT1jR/vhf79a0mYioiIiAoi8y18rZykTmDW4uNTMHbsQfj5Xdb1ubvbY/36rmjduqyEyYiIiKigMt/C11IldQKzdfHiU/j67sLt2xG6vu7dq+DXXzvCxcVGwmRERERUkJlv4UuSuH//Jby8ViMtTXvymq2tAosWtcegQbUh4056REREZELmfXIb5bqyZZ0xZEgdAED9+u4IDByOwYPrsOglIiIik+OIL+W6uXPbokKFQhgzpiEUCrnUcYiIiMhMcMSXTCYmJhn9+/tj7Vr9pclsba0wfnxjFr1ERESUq8x3xJffrJtUQMAj9O27C8HBUfD3vwVv79IoX57rJhMREZF0OOJLRpWWpsHUqUfh7b0WwcFRAAALCxnu3o2UNhgRERGZPfMd8SWju3cvEr6+u3Du3BNdX9OmpbBxYzeUKeMkXTAiIiIisPAlIxBCYP36qxg9+gDi4lIAAHK5DNOmNceECU0hl/OLBSIiIpKeGRe+nORrDC9fJuLTT/dhx44gXV+5cs7YsqUHGjQoLmEyIiIiIn1mXPiSMWg0AgEBj3S3hwypgwUL2sHOzkrCVERERERZ8Ttoei8uLjZYv74rXFyssWPHx1i1qjOLXiIiIsqTOOJLBrl58zkKFbKGm5udrq9167IIDv4C9vZKCZMRERERvZ0Zj/hyjq8hhBBYseIiPD1/xaBBf0AIoXc/i14iIiLK68y48KWcCg+PR5cu2zBy5P8hMTENBw7cxfr1V6WORURERGQQTnWgt/rzz7sYOHA3nj2L1/WNGlUPPXtWkzAVERERkeFY+FK2EhNTMWHCX1i06Lyur3BhG6xZ0wUdO1aUMBkRERHRuzHfwlfGOb5vcv36M/Tpsws3boTr+nx8KmDNms56J7URERER5SfmW/hStu7ejUS9en5ISVEDAFQqS8yZ0wajRtWHjL8sEBERUT7Gk9tIT/nyhdCrl3b+bq1abrh06VN89lkDFr1ERESU73HEl7JYssQHFSoUwtdfN4FSyT8iREREVDCY8YgvRzDj41Pw6ad7sX37Db1+BwclJk9uxqKXiIiIChRWNmbq4sWn8PXdhdu3I/D770Fo3LgkSpZ0lDoWERERkcmY8YiveVKrNZg58yS8vFbj9u0IAEBKihrXrj2TOBkRERGRaXHE14yEhESjXz9/nDjxUNdXv747Nm/ujgoVXCRMRkRERGR65lv4mtkqBdu23cCIEfsQHZ0MQPv2v/3WG1OnNoNCIZc4HREREZHpmW/hayZiYpLx+ef7sXHjNV1fqVKO2LSpG7y9S0uYjIiIiCh3sfAt4BISUnHgwF3d7d69q2PZsg5wclJJmIqIiIgo9/HktgKuaFE7rF7dGQ4OSmza1A1btvRg0UtERERmiSO+Bczdu5FwdlbBxcVG19e5cyUEB3+BQoWsJUxGREREJC0zHvEtWCe3CSGwdm0gatdegeHD90EIoXc/i14iIiIyd2Zc+BYckZGJ6NlzBwYP3oP4+FTs3HkTW7fe+O8HEhEREZkRTnXI544eDUa/fv548iRW1zdkSB107lxJwlREREREeQ8L33wqJUWN7747gjlzApA+q8HZWQU/v07o0aOqtOGIiIiI8iDzLXzz8QYWt269QJ8+OxEYGKbra9nSA+vXd0WJEg4SJiMiIiLKu8y38M2n/v33BerWXYnExDQAgEJhgZkzW2HsWC9YWOTfYp6IiIjI1HhyWz5TsaIL2revAACoUsUV588Pw/jxjVn0EhEREf0HjvjmMzKZDL/+2hEVKxbC5MnNYGOjkDoSERERUb5gxoVv3h8hTUxMxTff/IU2bcqiU6eMVRpcXGwwc2ZrCZMRERVcQgikpaVBrVZLHYWoQFMoFJDL5bn6mmZc+OZtV6+Gwdd3F/755zm2br2B69dHomhRO6ljEREVaCkpKQgNDUVCQoLUUYgKPJlMhhIlSsDOLvfqGxa+eYxGI7Bw4VlMmPA3UlK0ow1xcSm4ePEpOnasKHE6IqKCS6PRIDg4GHK5HO7u7rCysoIsH68ARJSXCSHw/PlzPH78GBUqVMi1kV8WvnnI06exGDhwNw4fvq/rq1XLDVu29EDVqoUlTEZEVPClpKRAo9GgZMmSsLGxkToOUYFXuHBhPHjwAKmpqSx8TS6P/Rbv738Tw4btRUREoq5v/Hgv/PhjSyiV5vtjIiLKbRYWXPCIKDdI8Y0KKyqJxcWlYOzYP7FqVaCuz93dHuvXd0Xr1mUlTEZERERUsLDwldjLl4n4/fcg3e1u3SrDz68TXFz4NRsRERGRMfH7HImVLOmIlSs7wtZWgVWrOmHnzp4seomIiHJBREQEihQpggcPHkgdpcBZsmQJOnfuLHWMLMy48JVmjm9ISDRiYpL1+nr1qo67d8dgyJC6PIOYiIgMMnDgQMhkMshkMlhaWqJUqVIYOXIkXr58meXYgIAA+Pj4wNnZGSqVCjVq1MDcuXOzXbP46NGj8PHxgYuLC2xsbFC1alWMHz8eT548yY23lStmzpyJTp06oUyZMlJHMZnjx4/D09MTKpUKZcuWxYoVK/7zMX///TcaN24Me3t7FCtWDN988w3S0tJ09z948ED3Zy7z5c8//9QdM2zYMFy4cAGnTp0yyft6V2Zc+Oa+bdtuoGbN5Rg9+kCW+7hGLxERvat27dohNDQUDx48wKpVq7B3716MGjVK7xh/f380a9YMJUqUwNGjR3Hr1i188cUX+PHHH/HJJ59ACKE7duXKlWjdujWKFi2KnTt3IigoCCtWrEB0dDTmzp2ba+8rJSXFZM+dmJiI1atXY+jQoe/1PKbM+L6Cg4Ph4+MDb29vBAYG4ttvv8WYMWOwc+fONz7m2rVr8PHxQbt27RAYGIht27Zhz549mDBhQpZj//rrL4SGhuouLVu21N2nVCrRp08fLF682CTv7Z0JMxMdHS0AiOgV1XPxNZNEv367BPC97rJjxz+59vpERPTfEhMTRVBQkEhMTJQ6ikEGDBggunTpotc3btw4UahQId3tuLg44eLiIrp3757l8Xv27BEAxLZt24QQQjx69EhYWVmJL7/8MtvXe/ny5RuzvHz5UgwbNkwUKVJEKJVKUa1aNbF3714hhBBTp04VtWrV0jt+/vz5onTp0lney08//SSKFSsmSpcuLSZMmCAaNmyY5bVq1KghpkyZoru9Zs0aUblyZaFUKkWlSpXE0qVL35hTCCF27twpXF1d9frS0tLE4MGDRZkyZYRKpRIVK1YUCxYs0Dsmu4xCCPH48WPRs2dP4eTkJAoVKiQ6d+4sgoODdY87f/68aN26tXBxcREODg7igw8+EJcuXXprxvf19ddfi8qVK+v1DR8+XDRq1OiNj5k4caKoV6+eXp+/v79QqVQiJiZGCCFEcHCwACACAwPf+vrHjh0TVlZWIiEhIdv73/Z3TlevRUe/9TUMxZPbTOz06RD07euPBw+idH29e1dHq1ZcsYGIKM/bVA+ID8v917UtCvS9+E4PvX//Pv78808oFApd36FDhxAREYGvvvoqy/GdOnVCxYoVsXXrVvTq1Qu///47UlJS8PXXX2f7/E5OTtn2azQatG/fHrGxsdi0aRPKlSuHoKAgg9dn/fvvv+Hg4IDDhw/rRqF//vln3Lt3D+XKlQMA/PPPP7h+/Tp27NgBAPDz88PUqVOxZMkS1KlTB4GBgRg2bBhsbW0xYMCAbF/nxIkTqFevXpb3UKJECfz2229wdXVFQEAAPv30UxQrVgw9e/Z8Y8aEhAS0aNEC3t7eOHHiBCwtLfHDDz+gXbt2uHbtGqysrBAbG4sBAwZg0aJFAIC5c+fCx8cHd+7cgb29fbYZN2/ejOHDh7/181q5ciV8fX2zve/MmTNo27atXt+HH36I1atXIzU1Ve/PSLrk5GSoVCq9PmtrayQlJeHSpUto3ry5rr9z585ISkpChQoVMHbsWHz00Ud6j6tXrx5SU1Nx/vx5NGvW7K3vI7ew8DWR1FQ1Zsw4gR9/PAmNRvsX18FBiWXLfODrW1PidERElCPxYUBc3p/Tum/fPtjZ2UGtViMpKQkAMG/ePN39t2/fBgBUqVIl28dXrlxZd8ydO3fg4OCAYsWKGZThr7/+wvnz53Hz5k1UrKjdabRsWcMHeWxtbbFq1SpYWVnp+mrWrIktW7Zg8uTJALQFYf369XWvM2PGDMydOxfdu3cHAHh4eCAoKAgrV658Y+H74MEDuLu76/UpFApMmzZNd9vDwwMBAQH47bff9Arf1zOuWbMGFhYWWLVqle5cnbVr18LJyQnHjh1D27Zt9aYBANqC1dnZGcePH0fHjh2zzdi5c2c0bNjwrZ+Xm5vbG+8LCwvLcr+bmxvS0tLw4sWLbH/GH374IRYsWICtW7eiZ8+eCAsLww8//AAACA0NBQDY2dlh3rx5aNKkCSwsLLBnzx706tUL69evR9++ffU+JycnJzx48ICFr/RMdxLZ3buR6Nt3F86dy/jHskmTkti0qTvKlHEy2esSEZGR2RbNF6/bokULLF++HAkJCVi1ahVu376N0aNHZzlOZJrH+3p/esGWuW2IK1euoESJErpi9F3VqFFDr+gFAF9fX6xZswaTJ0+GEAJbt27Fl19+CQB4/vw5Hj16hCFDhmDYsGG6x6SlpcHR0fGNr5OYmJhlZBMAVqxYgVWrVuHhw4dITExESkoKateu/daMly5dwt27d7OM3CYlJeHevXsAgPDwcEyZMgVHjhzBs2fPoFarkZCQgJCQkDdmtLe3f+NocE69/rNM/zPwpp9x27ZtMXv2bIwYMQL9+vWDUqnE5MmTcerUKd3ovaurK8aOHat7TL169fDy5UvMmjVLr/AFtKPFCQkJ7/UejMmMC1/TuHnzOerX90N8fCoAQC6X4fvvm2PChKawtOS5hERE+co7TjfIbba2tihfvjwAYNGiRWjRogWmTZuGGTNmAICuGL158yYaN26c5fG3bt1C1apVdcdGR0cjNDTUoFFfa2vrt95vYWGRpfBOTU3N9r28rk+fPpgwYQIuX76MxMREPHr0CJ988gkA7fQEQDvd4fXR0bdNs3B1dc2y8sVvv/2GsWPHYu7cufDy8oK9vT1mz56Nc+fOvTWjRqOBp6cnNm/enOV1ChcuDEC7+sbz58+xYMEClC5dGkqlEl5eXm89Oe59pzoULVoUYWH6U3XCw8NhaWkJFxeXNz7nuHHjMHbsWISGhsLZ2RkPHjzAxIkT4eHh8cbHNGrUCKtWrcrSHxkZqfsM8gIWvkZWubIrvL1L488/76JcOWds3twdDRuWkDoWERGZkalTp6J9+/YYOXIk3N3d0bZtWxQqVAhz587NUvju2bMHd+7c0RXJH330ESZMmIBZs2Zh/vz5WZ47Kioq23m+NWvWxOPHj3H79u1sR30LFy6MsLAwvRHlK1eu5Oj9lChRAh988AE2b96MxMREtG7dWvcVvpubG4oXL4779++/sQDMTp06dbBp0ya9vpMnT6Jx48Z6K2Kkj9i+Td26dbF9+3YUKVIEDg4O2R5z8uRJLFu2DD4+PgCAR48e4cWLF2993ved6uDl5YW9e/fq9R06dAj16tXLdn5vZjKZTDcVZOvWrShZsiTq1q37xuMDAwOz/KJ07949JCUloU6dOm99rVxl1FPl8oGMVR1qmOw1QkNjxRdfHBCxsckmew0iIjKugrSqgxBCeHp6is8++0x3+/fffxdyuVwMGzZMXL16VQQHB4tVq1YJZ2dn8dFHHwmNRqM7dunSpUImk4nBgweLY8eOiQcPHohTp06JTz/9VIwbN+6NWZo3by6qV68uDh06JO7fvy/2798vDhw4IIQQIigoSMhkMvHzzz+Lu3fviiVLlghnZ+dsV3XIzq+//irc3d2Fq6ur2Lhxo959fn5+wtraWixYsED8+++/4tq1a2LNmjVi7ty5b8x67do1YWlpKSIjI3V9CxYsEA4ODuLPP/8U//77r/juu++Eg4OD3moU2WWMj48XFSpUEM2bNxcnTpwQ9+/fF8eOHRNjxowRjx49EkIIUbt2bdGmTRsRFBQkzp49K7y9vYW1tbWYP3/+GzO+r/v37wsbGxsxduxYERQUJFavXi0UCoXYsWOH7phdu3aJSpUq6T1u1qxZ4tq1a+LGjRti+vTpQqFQCH9/f93969atE5s3bxZBQUHi1q1bYvbs2UKhUIh58+bpPc/atWtF2bJl35hPilUdzLfwXVnzvZ8rOTlNfP31IXH48D0jJCMiIikVtMJ38+bNwsrKSoSEhOj6Tpw4Idq1ayccHR2FlZWVqFq1qpgzZ45IS0vL8vjDhw+LDz/8UDg7OwuVSiUqV64svvrqK/H06dM3ZomIiBCDBg0SLi4uQqVSierVq4t9+/bp7l++fLkoWbKksLW1Ff379xc//vhjjgvfly9fCqVSKWxsbERsbGy277d27drCyspKODs7iw8++EDs2rXrjVmFEKJRo0ZixYoVuttJSUli4MCBwtHRUTg5OYmRI0eKCRMm/GfhK4QQoaGhon///sLV1VUolUpRtmxZMWzYMF3hdvnyZVGvXj2hVCpFhQoVxO+//y5Kly5t0sJXCO2SYnXq1BFWVlaiTJkyYvny5Xr3r127Vrw+DtqiRQvh6OgoVCqVaNiwodi/f7/e/evWrRNVqlQRNjY2wt7eXnh6emb5ZUQIIdq2bStmzpz5xmxSFL4yId4w072AiomJgaOjI6JX1oTDp1ff+Xlu3XqBPn12IjAwDO7u9rh2bQS3GiYiyseSkpIQHBwMDw+PbE96ooJn//79+Oqrr3Djxg1YWPA8HGO6ceMGWrVqhdu3b7/xJMO3/Z3T1WvR0W+cPvIu+FM2kBACK1ZcRN26KxEYqJ0w/vx5PAICHkmcjIiIiAzh4+OD4cOHF6htmPOKp0+fYsOGDW9dWUMKPLnNAOHh8Rg6dA/27r2t66tSxRVbtvRA7doSLXlDRERE7+yLL76QOkKB9PrGGXmFGRe+hq1R+OefdzFw4G48exav6xs1qh5mz24LG5u3nxlJRERERNIz48I3ZxITUzFhwl9YtOi8rq9wYRusWdMFHTu+3yLdRERERJR7WPj+h6dPY7F6daDuto9PBaxZ0xlubnYSpiIiIlMxs3O+iSQjxd81ntz2H8qVK4RFi9pDpbLEkiXtsW9fbxa9REQFUPqC/nlpe1Wigix917q37bBnbOY74vuGPaqfPo2Fk5NKb97uoEG10aqVB0qXdsqlcERElNvkcjmcnJwQHh4OALCxsdHtMEZExqXRaPD8+XPY2NjA0jL3ylHzLXyz4e9/E8OG7cXHH1fF8uUddf0ymYxFLxGRGShaVLtCT3rxS0SmY2FhgVKlSuXqL5gsfAHExaVg7Ng/sWqVdi7vihWX0KFDRZ68RkRkZmQyGYoVK4YiRYogNTVV6jhEBZqVlVWubxxi9oXvhQtP4Ou7C3fuROr6unWrDC+vEhKmIiIiKcnl8lydd0hEuUPyk9uWLVum26rO09MTJ0+efOvxx48fh6enJ1QqFcqWLYsVK1a80+uqNTLMnHkSjRuv0RW9NjYKrFrVCTt39uT2w0REREQFjKSF7/bt2/Hll19i0qRJCAwMhLe3N9q3b4+QkJBsjw8ODoaPjw+8vb0RGBiIb7/9FmPGjMHOnTsNfu2Ocxrg22+PIC1NAwCoX98dV64Mx5AhdXkyAxEREVEBJBMSLljYsGFD1K1bF8uXL9f1ValSBV27dsXMmTOzHP/NN99gz549uHnzpq5vxIgRuHr1Ks6cOZOj14yJiXm1b/QEACpYWMgwcWJTTJ3aDAoFv9YiIiIiklp6vRYdHQ0HBwejPa9kc3xTUlJw6dIlTJgwQa+/bdu2CAgIyPYxZ86cybL384cffojVq1cjNTVVtwZjZsnJyUhOTtbdjo6OTr8HJUo4ws+vIxo3LoXExHgkJr7feyIiIiKi9xcTEwPA+JtcSFb4vnjxAmq1Gm5ubnr9bm5uCAsLy/YxYWFh2R6flpaGFy9eoFixYlkeM3PmTEybNi2bZ5uPx4+B9u0nvvN7ICIiIiLTiYiIePVNvXFIvqrD6/NphRBvnWOb3fHZ9aebOHEixo0bp7sdFRWF0qVLIyQkxKgfJOVNMTExKFmyJB49emTUr0oob+LP27zw521e+PM2L9HR0ShVqhQKFSpk1OeVrPB1dXWFXC7PMrobHh6eZVQ3XdGiRbM93tLSEi4uLtk+RqlUQqlUZul3dHTkXxwz4uDgwJ+3GeHP27zw521e+PM2L8Ze51eyVR2srKzg6emJw4cP6/UfPnwYjRs3zvYxXl5eWY4/dOgQ6tWrl+38XiIiIiKidJIuZzZu3DisWrUKa9aswc2bNzF27FiEhIRgxIgRALTTFPr37687fsSIEXj48CHGjRuHmzdvYs2aNVi9ejW++uorqd4CEREREeUTks7x7dWrFyIiIjB9+nSEhoaievXq2L9/P0qXLg0ACA0N1VvT18PDA/v378fYsWOxdOlSuLu7Y9GiRejRo0eOX1OpVGLq1KnZTn+ggoc/b/PCn7d54c/bvPDnbV5M9fOWdB1fIiIiIqLcIvmWxUREREREuYGFLxERERGZBRa+RERERGQWWPgSERERkVkokIXvsmXL4OHhAZVKBU9PT5w8efKtxx8/fhyenp5QqVQoW7YsVqxYkUtJyRgM+Xnv2rULbdq0QeHCheHg4AAvLy8cPHgwF9PS+zL073e606dPw9LSErVr1zZtQDIqQ3/eycnJmDRpEkqXLg2lUoly5cphzZo1uZSW3pehP+/NmzejVq1asLGxQbFixTBo0CBERETkUlp6HydOnECnTp3g7u4OmUyG3bt3/+djjFKviQJm27ZtQqFQCD8/PxEUFCS++OILYWtrKx4+fJjt8ffv3xc2Njbiiy++EEFBQcLPz08oFAqxY8eOXE5O78LQn/cXX3whfvnlF3H+/Hlx+/ZtMXHiRKFQKMTly5dzOTm9C0N/3umioqJE2bJlRdu2bUWtWrVyJyy9t3f5eXfu3Fk0bNhQHD58WAQHB4tz586J06dP52JqeleG/rxPnjwpLCwsxMKFC8X9+/fFyZMnRbVq1UTXrl1zOTm9i/3794tJkyaJnTt3CgDC39//rccbq14rcIVvgwYNxIgRI/T6KleuLCZMmJDt8V9//bWoXLmyXt/w4cNFo0aNTJaRjMfQn3d2qlatKqZNm2bsaGQC7/rz7tWrl/juu+/E1Kn/397dxzR1/X8AfxdKoVJApxMqRRhilU6cUxCBTYJD2TBCzBCdVWHBB8IMzgeIiVNqFGe+DlxQcMviQE11MqHGmTlRQQNDDSV0AUXH8GESdfM5oCgCn98fhvuz8qAtTwM+r+Qm3HPPPfdz7kn108O5lyROfPsQU8f72LFj5ODgQPfu3euJ8FgXM3W8t23bRu7u7kZlaWlppFAoui1G1j3eJPHtqnytXy11aGhoQGlpKWbMmGFUPmPGDBQXF7d5ztmzZ1vVDwkJgV6vx/Pnz7stVtZ55oz3q5qbm1FbW4u33nqrO0JkXcjc8c7MzER1dTWSkpK6O0TWhcwZ7yNHjsDb2xv/+9//4OzsDKVSiTVr1qC+vr4nQmadYM54+/v7o6amBr/++iuICP/88w8OHTqEmTNn9kTIrId1Vb7Wq3+5ravdvXsXTU1NcHR0NCp3dHTE7du32zzn9u3bbdZvbGzE3bt3IZfLuy1e1jnmjPerUlJS8PjxY0RGRnZHiKwLmTPeVVVVWLt2LQoLCyEW96t/7vo9c8b7ypUrKCoqgo2NDXQ6He7evYu4uDjcv3+f1/n+x5kz3v7+/tBqtZg7dy6ePn2KxsZGhIWFYceOHT0RMuthXZWv9asZ3xYikchon4halb2uflvl7L/J1PFuceDAAWg0Ghw8eBDDhw/vrvBYF3vT8W5qasL8+fOxceNGKJXKngqPdTFTPt/Nzc0QiUTQarWYPHkyQkNDkZqaiqysLJ717SNMGe+LFy8iPj4eGzZsQGlpKX777TdcvXoVsbGxPREq6wVdka/1qymQYcOGwdLSstW3w3///bfVt4QWTk5ObdYXi8UYOnRot8XKOs+c8W5x8OBBxMTE4Oeff0ZwcHB3hsm6iKnjXVtbC71ej7KyMixfvhzAi8SIiCAWi5GXl4dp06b1SOzMdOZ8vuVyOZydneHg4CCUeXp6gohQU1OD0aNHd2vMzHzmjPfXX3+NgIAAJCQkAADGjx8PW1tbfPjhh9i8eTP/xraf6ap8rV/N+EokEkyaNAknTpwwKj9x4gT8/f3bPMfPz69V/by8PHh7e8PKyqrbYmWdZ854Ay9meqOjo7F//35eC9aHmDre9vb2KC8vh8FgELbY2FiMGTMGBoMBvr6+PRU6M4M5n++AgADcvHkTdXV1Qtmff/4JCwsLKBSKbo2XdY454/3kyRNYWBinMZaWlgD+fyaQ9R9dlq+Z9ChcH9DyOpTdu3fTxYsX6csvvyRbW1u6du0aERGtXbuWFi5cKNRveT3GypUr6eLFi7R7925+nVkfYup479+/n8RiMaWnp9OtW7eE7eHDh73VBWYCU8f7VfxWh77F1PGura0lhUJBERERdOHCBTpz5gyNHj2aFi9e3FtdYCYwdbwzMzNJLBZTRkYGVVdXU1FREXl7e9PkyZN7qwvMBLW1tVRWVkZlZWUEgFJTU6msrEx4fV135Wv9LvElIkpPTydXV1eSSCQ0ceJEOnPmjHAsKiqKAgMDjeqfPn2a3n//fZJIJOTm5ka7du3q4YhZZ5gy3oGBgQSg1RYVFdXzgTOzmPr5fhknvn2PqeNdWVlJwcHBJJVKSaFQ0KpVq+jJkyc9HDUzl6njnZaWRiqViqRSKcnlclKr1VRTU9PDUTNzFBQUdPj/cXflayIi/n0AY4wxxhjr//rVGl/GGGOMMcbaw4kvY4wxxhgbEDjxZYwxxhhjAwInvowxxhhjbEDgxJcxxhhjjA0InPgyxhhjjLEBgRNfxhhjjDE2IHDiyxhjjDHGBgROfBljrJM0Gg0mTJjQa9fPysrC4MGDe+36neXm5oZvv/22wzq9fY8ZY/0DJ76Msf8skUjU4RYdHd3bIXaZ6OjoNvv4119/9XZoyMrKMopJLpcjMjISV69e7ZL2S0pKsHTpUmFfJBLh8OHDRnXWrFmDU6dOdcn1GGMDl7i3A2CMsfbcunVL+PngwYPYsGEDLl++LJRJpdLeCKvbfPzxx8jMzDQqe/vtt3spGmP29va4fPkyiAiXLl3CsmXLEBYWBoPBAEtLy061/SZ9lMlkkMlknboOY4zxjC9j7D/LyclJ2BwcHCASiYR9KysrxMbGQqFQYNCgQfDy8sKBAweEc+/cuQMnJyds2bJFKDt//jwkEgny8vIAANXV1QgPD4ejoyNkMhl8fHxw8uTJ18a1detWODo6ws7ODjExMXj69GmrOpmZmfD09ISNjQ3Gjh2LjIyM17ZrbW1t1GcnJydYWloiNTUVXl5esLW1hYuLC+Li4lBXV9duO3/88QeCgoJgZ2cHe3t7TJo0CXq9Xjiek5ODd999F9bW1nBzc0NKSsprY2u593K5HEFBQUhKSkJFRYUwI71r1y6MGjUKEokEY8aMwb59+4zO12g0GDlyJKytrTFixAjEx8cLx15e6uDm5gYAmD17NkQikbD/8lKH48ePw8bGBg8fPjS6Rnx8PAIDAzvVT8ZY/8aJL2OsT3r69CkmTZqEo0ePoqKiAkuXLsXChQtx/vx5AC9mEX/88UdoNBro9XrU1dVhwYIFiIuLw4wZMwAAdXV1CA0NxcmTJ1FWVoaQkBDMmjULf//9d7vXzc7ORlJSEpKTk6HX6yGXy1sltT/88APWrVuH5ORkVFZWYsuWLVi/fj327NljVl8tLCyQlpaGiooK7NmzB/n5+UhMTGy3vlqthkKhQElJCUpLS7F27VpYWVkBAEpLSxEZGYl58+ahvLwcGo0G69evR1ZWlkkxtcy2P3/+HDqdDitWrMDq1atRUVGBZcuW4fPPP0dBQQEA4NChQ9i+fTu+//57VFVV4fDhw/Dy8mqz3ZKSEgAvvjjcunVL2H9ZcHAwBg8ejJycHKGsqakJ2dnZUKvVXdpPxlg/Q4wx1gdkZmaSg4NDh3VCQ0Np9erVRmVxcXGkVCpJrVbTuHHjqL6+vsM2VCoV7dixo93jfn5+FBsba1Tm6+tL7733nrDv4uJC+/fvN6qzadMm8vPza7fdqKgosrS0JFtbW2GLiIhos252djYNHTpU2H/13tjZ2VFWVlab586fP5+mT59uVJaQkEAqlard2F5t/8aNGzRlyhRSKBT07Nkz8vf3pyVLlhidM2fOHAoNDSUiopSUFFIqldTQ0NBm+66urrR9+3ZhHwDpdDqjOklJSUb3OD4+nqZNmybsHz9+nCQSCd2/f9/sfjLG+j+e8WWM9UlNTU1ITk7G+PHjMXToUMhkMuTl5bWarf3mm2/Q2NiI7OxsaLVa2NjYCMceP36MxMREqFQqDB48GDKZDJcuXepwxreyshJ+fn5GZS/v37lzBzdu3EBMTIywLlUmk2Hz5s2orq7usE9BQUEwGAzClpaWBgAoKCjA9OnT4ezsDDs7OyxatAj37t3D48eP22xn1apVWLx4MYKDg7F161aj61ZWViIgIMCofkBAAKqqqtDU1NRubI8ePYJMJhOWWzQ0NCA3NxcSiaTdNisrKwEAc+bMQX19Pdzd3bFkyRLodDo0NjZ2eC9eR61W4/Tp07h58yYAQKvVIjQ0FEOGDOlUPxlj/RsnvoyxPiklJQXbt29HYmIi8vPzYTAYEBISgoaGBqN6V65cwc2bN9Hc3Izr168bHUtISEBOTg6Sk5NRWFgIg8EALy+vVm2Yorm5GcCL5Q4vJ7EVFRU4d+5ch+fa2trCw8ND2ORyOa5fv47Q0FCMGzcOOTk5KC0tRXp6OoAXywzaotFocOHCBcycORP5+flQqVTQ6XQAACKCSCQyqk9Er+2XnZ0dDAYDysvLUVdXh9LSUvj4+AjH22qzpczFxQWXL19Geno6pFIp4uLiMHXq1HbjfxOTJ0/GqFGj8NNPP6G+vh46nQ4LFixo8/qm9JMx1r/xWx0YY31SYWEhwsPDhWSnubkZVVVV8PT0FOo0NDRArVZj7ty5GDt2LGJiYlBeXg5HR0ehjejoaMyePRvAizW/165d6/C6np6eOHfuHBYtWiSUvZzQOjo6wtnZGVeuXBHWm3aGXq9HY2MjUlJSYGHxYq4iOzv7tecplUoolUqsXLkSn332GTIzMzF79myoVCoUFRUZ1S0uLoZSqezw7QwWFhbw8PBo85inpyeKioqM7klxcbHRWEilUoSFhSEsLAxffPEFxo4di/LyckycOLFVe1ZWVm80Kzt//nxotVooFApYWFhg5syZwjFz+8kY69848WWM9UkeHh7IyclBcXExhgwZgtTUVNy+fdso2Vq3bh0ePXqEtLQ0yGQyHDt2DDExMTh69KjQRm5uLmbNmgWRSIT169cLM7btWbFiBaKiouDt7Y0PPvgAWq0WFy5cgLu7u1BHo9EgPj4e9vb2+OSTT/Ds2TPo9Xo8ePAAq1atMqmfo0aNQmNjI3bs2IFZs2bh999/x3fffddu/fr6eiQkJCAiIgLvvPMOampqUFJSgk8//RQAsHr1avj4+GDTpk2YO3cuzp49i507d77RWyfak5CQgMjISEycOBEfffQRfvnlF+Tm5gpvyMjKykJTUxN8fX0xaNAg7Nu3D1KpFK6urm225+bmhlOnTiEgIADW1tbC8oVXqdVqbNy4EcnJyYiIiDBaxtId/WSM9QO9usKYMcbe0KsPWN27d4/Cw8NJJpPR8OHD6auvvqJFixZReHg4EREVFBSQWCymwsJC4Zzr16+Tg4MDZWRkEBHR1atXKSgoiKRSKbm4uNDOnTspMDCQVqxY0WEsycnJNGzYMJLJZBQVFUWJiYlGD14REWm1WpowYQJJJBIaMmQITZ06lXJzc9ttMyoqSoj9VampqSSXy0kqlVJISAjt3buXANCDBw9a3Ztnz57RvHnzyMXFhSQSCY0YMYKWL19u9FDfoUOHSKVSkZWVFY0cOZK2bdvWYX/f5MHCjIwMcnd3JysrK1IqlbR3717hmE6nI19fX7K3tydbW1uaMmUKnTx5Ujj+6sNtR44cIQ8PDxKLxeTq6kpErR9ua+Hj40MAKD8/v9UxU/vJGOv/RES86IkxxhhjjPV//HAbY4wxxhgbEDjxZYwxxhhjAwInvowxxhhjbEDgxJcxxhhjjA0InPgyxhhjjLEBgRNfxhhjjDE2IHDiyxhjjDHGBgROfBljjDHG2IDAiS9jjDHGGBsQOPFljDHGGGMDAie+jDHGGGNsQPg/Ogge/dXZYc4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=50) \n",
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "pipeline_rf.set_params(**best_params_rf)\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Acurácia do modelo Random Forest: {accuracy_rf:.2f}')\n",
    "\n",
    "y_prob_rf = pipeline_rf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "print(f'ROC-AUC do modelo Random Forest: {roc_auc_rf:.2f}')\n",
    "\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Matriz de Confusão Random Forest:')\n",
    "print(conf_matrix_rf)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_rf))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC Random Forest')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "pipeline_xgb = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('xgb', xgb.XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'xgb__n_estimators': trial.suggest_int('xgb__n_estimators', 50, 200),\n",
    "        'xgb__max_depth': trial.suggest_int('xgb__max_depth', 3, 10),\n",
    "        'xgb__learning_rate': trial.suggest_float('xgb__learning_rate', 0.01, 0.3),\n",
    "        'xgb__subsample': trial.suggest_float('xgb__subsample', 0.6, 1.0),\n",
    "        'xgb__colsample_bytree': trial.suggest_float('xgb__colsample_bytree', 0.6, 1.0),\n",
    "    }\n",
    "    pipeline_xgb.set_params(**params)\n",
    "    cv_scores = cross_val_score(pipeline_xgb, X_train, y_train, cv=5)\n",
    "    return cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 10:55:18,430] A new study created in memory with name: no-name-dd51dbfa-5f42-46aa-883d-0e3dfa1a288b\n",
      "[I 2023-09-04 10:55:41,424] Trial 0 finished with value: 0.9416989567809239 and parameters: {'xgb__n_estimators': 106, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.06350897650544718, 'xgb__subsample': 0.9305473633620215, 'xgb__colsample_bytree': 0.7899988371053346}. Best is trial 0 with value: 0.9416989567809239.\n",
      "[I 2023-09-04 10:56:04,536] Trial 1 finished with value: 0.9412021857923497 and parameters: {'xgb__n_estimators': 155, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.28447440295247745, 'xgb__subsample': 0.9873413763532487, 'xgb__colsample_bytree': 0.771839592575815}. Best is trial 0 with value: 0.9416989567809239.\n",
      "[I 2023-09-04 10:56:15,366] Trial 2 finished with value: 0.941818181818182 and parameters: {'xgb__n_estimators': 73, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.19350768708612093, 'xgb__subsample': 0.9866950980057086, 'xgb__colsample_bytree': 0.8288955665725838}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:56:28,786] Trial 3 finished with value: 0.9415797317436662 and parameters: {'xgb__n_estimators': 79, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.2847461099004066, 'xgb__subsample': 0.8822129619000857, 'xgb__colsample_bytree': 0.9454476850493303}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:56:46,298] Trial 4 finished with value: 0.9406656731246896 and parameters: {'xgb__n_estimators': 194, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.2544353025625566, 'xgb__subsample': 0.8754215626412083, 'xgb__colsample_bytree': 0.6877453815940008}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:57:17,504] Trial 5 finished with value: 0.9405265772478888 and parameters: {'xgb__n_estimators': 193, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.24883819834577903, 'xgb__subsample': 0.9154835007952175, 'xgb__colsample_bytree': 0.9691414142550878}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:57:54,654] Trial 6 finished with value: 0.939652260307998 and parameters: {'xgb__n_estimators': 164, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.1853513526791349, 'xgb__subsample': 0.7842261273689815, 'xgb__colsample_bytree': 0.825566233302163}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:58:04,487] Trial 7 finished with value: 0.9415201192250373 and parameters: {'xgb__n_estimators': 56, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.17213239740256872, 'xgb__subsample': 0.760911176850512, 'xgb__colsample_bytree': 0.6333631742464668}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:58:11,904] Trial 8 finished with value: 0.940327868852459 and parameters: {'xgb__n_estimators': 68, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.2887987389319727, 'xgb__subsample': 0.8354247457846814, 'xgb__colsample_bytree': 0.6451925279045824}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:58:19,354] Trial 9 finished with value: 0.9390362642821659 and parameters: {'xgb__n_estimators': 87, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.14674096576206722, 'xgb__subsample': 0.875369212650755, 'xgb__colsample_bytree': 0.9491091084070817}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:58:47,547] Trial 10 finished with value: 0.9403874813710879 and parameters: {'xgb__n_estimators': 113, 'xgb__max_depth': 10, 'xgb__learning_rate': 0.013604329603199461, 'xgb__subsample': 0.6582948845237042, 'xgb__colsample_bytree': 0.8494183976128851}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:59:08,021] Trial 11 finished with value: 0.94173869846001 and parameters: {'xgb__n_estimators': 109, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.07372758808739743, 'xgb__subsample': 0.9734949929931391, 'xgb__colsample_bytree': 0.7626699217349435}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:59:28,153] Trial 12 finished with value: 0.9416989567809241 and parameters: {'xgb__n_estimators': 136, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.11618906482931393, 'xgb__subsample': 0.997772442691569, 'xgb__colsample_bytree': 0.7194671782224497}. Best is trial 2 with value: 0.941818181818182.\n",
      "[I 2023-09-04 10:59:46,707] Trial 13 finished with value: 0.9418777943368107 and parameters: {'xgb__n_estimators': 96, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.0866903392739773, 'xgb__subsample': 0.9637076285233412, 'xgb__colsample_bytree': 0.8632555678717754}. Best is trial 13 with value: 0.9418777943368107.\n",
      "[I 2023-09-04 10:59:57,789] Trial 14 finished with value: 0.9411624441132638 and parameters: {'xgb__n_estimators': 88, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.2058574847856009, 'xgb__subsample': 0.998874820258342, 'xgb__colsample_bytree': 0.8809505432904899}. Best is trial 13 with value: 0.9418777943368107.\n",
      "[I 2023-09-04 11:00:08,301] Trial 15 finished with value: 0.9417784401390957 and parameters: {'xgb__n_estimators': 53, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.13159719983871243, 'xgb__subsample': 0.9406921517950708, 'xgb__colsample_bytree': 0.8860455964478396}. Best is trial 13 with value: 0.9418777943368107.\n",
      "[I 2023-09-04 11:00:40,139] Trial 16 finished with value: 0.9402483854942872 and parameters: {'xgb__n_estimators': 131, 'xgb__max_depth': 10, 'xgb__learning_rate': 0.1973608699613484, 'xgb__subsample': 0.9231911900218117, 'xgb__colsample_bytree': 0.8851033621447395}. Best is trial 13 with value: 0.9418777943368107.\n",
      "[I 2023-09-04 11:00:51,587] Trial 17 finished with value: 0.9408445106805763 and parameters: {'xgb__n_estimators': 94, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.10921688503305402, 'xgb__subsample': 0.9437460398448518, 'xgb__colsample_bytree': 0.8165827233294752}. Best is trial 13 with value: 0.9418777943368107.\n",
      "[I 2023-09-04 11:01:04,400] Trial 18 finished with value: 0.9412816691505217 and parameters: {'xgb__n_estimators': 70, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.16791757206999908, 'xgb__subsample': 0.9603544932975059, 'xgb__colsample_bytree': 0.915258582658725}. Best is trial 13 with value: 0.9418777943368107.\n",
      "[I 2023-09-04 11:01:18,666] Trial 19 finished with value: 0.9420566318926975 and parameters: {'xgb__n_estimators': 98, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.14985834483049282, 'xgb__subsample': 0.8379780799119575, 'xgb__colsample_bytree': 0.8142056044774302}. Best is trial 19 with value: 0.9420566318926975.\n",
      "[I 2023-09-04 11:01:50,356] Trial 20 finished with value: 0.9417983109786388 and parameters: {'xgb__n_estimators': 120, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.08442976349149241, 'xgb__subsample': 0.8321659599329998, 'xgb__colsample_bytree': 0.9781090439166753}. Best is trial 19 with value: 0.9420566318926975.\n",
      "[I 2023-09-04 11:02:11,499] Trial 21 finished with value: 0.9419771485345256 and parameters: {'xgb__n_estimators': 98, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.14952144466644463, 'xgb__subsample': 0.9665787892948231, 'xgb__colsample_bytree': 0.8381105699565489}. Best is trial 19 with value: 0.9420566318926975.\n",
      "[I 2023-09-04 11:02:27,893] Trial 22 finished with value: 0.9402881271733732 and parameters: {'xgb__n_estimators': 100, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.1485804307372791, 'xgb__subsample': 0.9026552685958745, 'xgb__colsample_bytree': 0.8566041678812621}. Best is trial 19 with value: 0.9420566318926975.\n",
      "[I 2023-09-04 11:03:02,469] Trial 23 finished with value: 0.9418380526577248 and parameters: {'xgb__n_estimators': 140, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.10496962366198692, 'xgb__subsample': 0.9539466119844131, 'xgb__colsample_bytree': 0.8039407266329962}. Best is trial 19 with value: 0.9420566318926975.\n",
      "[I 2023-09-04 11:03:22,363] Trial 24 finished with value: 0.9420963735717833 and parameters: {'xgb__n_estimators': 122, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.13936467547023174, 'xgb__subsample': 0.9588528165922979, 'xgb__colsample_bytree': 0.7513494147728076}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:03:39,705] Trial 25 finished with value: 0.9411227024341778 and parameters: {'xgb__n_estimators': 120, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.13755682765058777, 'xgb__subsample': 0.9099317561911051, 'xgb__colsample_bytree': 0.7394380266568443}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:04:04,029] Trial 26 finished with value: 0.9417784401390958 and parameters: {'xgb__n_estimators': 147, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.16178027358667924, 'xgb__subsample': 0.8348326565759047, 'xgb__colsample_bytree': 0.789943231221886}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:04:24,281] Trial 27 finished with value: 0.9411227024341778 and parameters: {'xgb__n_estimators': 172, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.12928847487422018, 'xgb__subsample': 0.7409865954103789, 'xgb__colsample_bytree': 0.7572723008402581}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:04:44,318] Trial 28 finished with value: 0.9417585692995528 and parameters: {'xgb__n_estimators': 128, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.16178084631594597, 'xgb__subsample': 0.8956973796464608, 'xgb__colsample_bytree': 0.7159270499217668}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:04:58,387] Trial 29 finished with value: 0.9410233482364629 and parameters: {'xgb__n_estimators': 107, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.11860573225924492, 'xgb__subsample': 0.9475496128393818, 'xgb__colsample_bytree': 0.793081332058544}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:05:10,648] Trial 30 finished with value: 0.939076005961252 and parameters: {'xgb__n_estimators': 115, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.14909306489820262, 'xgb__subsample': 0.9189611283853784, 'xgb__colsample_bytree': 0.7816346930961513}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:05:34,392] Trial 31 finished with value: 0.9416989567809241 and parameters: {'xgb__n_estimators': 99, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.08965902686848819, 'xgb__subsample': 0.9660350632727336, 'xgb__colsample_bytree': 0.8430416133475868}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:05:50,529] Trial 32 finished with value: 0.9410233482364629 and parameters: {'xgb__n_estimators': 86, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.06366137347770282, 'xgb__subsample': 0.9625843057560719, 'xgb__colsample_bytree': 0.8198662906278661}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:06:05,951] Trial 33 finished with value: 0.9413412816691504 and parameters: {'xgb__n_estimators': 99, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.09902474772528658, 'xgb__subsample': 0.9770749287819568, 'xgb__colsample_bytree': 0.7872873142729443}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:06:20,111] Trial 34 finished with value: 0.9420168902136116 and parameters: {'xgb__n_estimators': 77, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.120672118193179, 'xgb__subsample': 0.9369018960979224, 'xgb__colsample_bytree': 0.8085017061230796}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:06:32,202] Trial 35 finished with value: 0.9417188276204669 and parameters: {'xgb__n_estimators': 76, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1319147095518215, 'xgb__subsample': 0.9339072978477914, 'xgb__colsample_bytree': 0.8092346187283834}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:06:47,312] Trial 36 finished with value: 0.9417784401390958 and parameters: {'xgb__n_estimators': 82, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.11687279680633851, 'xgb__subsample': 0.9843861696629612, 'xgb__colsample_bytree': 0.7547541499323858}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:06:59,198] Trial 37 finished with value: 0.9414605067064084 and parameters: {'xgb__n_estimators': 62, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.1484064353933501, 'xgb__subsample': 0.8666868292739276, 'xgb__colsample_bytree': 0.8328662378196673}. Best is trial 24 with value: 0.9420963735717833.\n",
      "[I 2023-09-04 11:07:14,078] Trial 38 finished with value: 0.9421162444113265 and parameters: {'xgb__n_estimators': 77, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.18953805359503179, 'xgb__subsample': 0.9314897718808169, 'xgb__colsample_bytree': 0.7685800191687187}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:07:26,104] Trial 39 finished with value: 0.941758569299553 and parameters: {'xgb__n_estimators': 66, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.18245230476008356, 'xgb__subsample': 0.8918125677329986, 'xgb__colsample_bytree': 0.7680611877772167}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:07:41,000] Trial 40 finished with value: 0.9414207650273225 and parameters: {'xgb__n_estimators': 61, 'xgb__max_depth': 9, 'xgb__learning_rate': 0.20649695288174208, 'xgb__subsample': 0.922542047376144, 'xgb__colsample_bytree': 0.7328289901988987}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:07:52,594] Trial 41 finished with value: 0.9415201192250372 and parameters: {'xgb__n_estimators': 77, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.17590003723766467, 'xgb__subsample': 0.9350227641822736, 'xgb__colsample_bytree': 0.8022133630581806}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:08:09,837] Trial 42 finished with value: 0.9418777943368107 and parameters: {'xgb__n_estimators': 92, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.15902391307951072, 'xgb__subsample': 0.9819676096345357, 'xgb__colsample_bytree': 0.8229977941340753}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:08:22,506] Trial 43 finished with value: 0.9415598609041232 and parameters: {'xgb__n_estimators': 80, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.18403231359649858, 'xgb__subsample': 0.8620309528552995, 'xgb__colsample_bytree': 0.775462142507899}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:08:36,881] Trial 44 finished with value: 0.9416194734227521 and parameters: {'xgb__n_estimators': 105, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.13753409771351502, 'xgb__subsample': 0.9154470309190019, 'xgb__colsample_bytree': 0.8020240561960104}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:08:51,992] Trial 45 finished with value: 0.9414605067064082 and parameters: {'xgb__n_estimators': 71, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.22168030494326235, 'xgb__subsample': 0.8864653278876777, 'xgb__colsample_bytree': 0.8353469730954229}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:09:10,904] Trial 46 finished with value: 0.9421162444113265 and parameters: {'xgb__n_estimators': 122, 'xgb__max_depth': 6, 'xgb__learning_rate': 0.17153170280776855, 'xgb__subsample': 0.9976731066017707, 'xgb__colsample_bytree': 0.774792729845166}. Best is trial 38 with value: 0.9421162444113265.\n",
      "[I 2023-09-04 11:09:40,506] Trial 47 finished with value: 0.9422950819672131 and parameters: {'xgb__n_estimators': 154, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.16839788509928802, 'xgb__subsample': 0.9954103069568692, 'xgb__colsample_bytree': 0.7746609012142811}. Best is trial 47 with value: 0.9422950819672131.\n",
      "[I 2023-09-04 11:10:11,921] Trial 48 finished with value: 0.941679085941381 and parameters: {'xgb__n_estimators': 160, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.175186182682999, 'xgb__subsample': 0.999554656358562, 'xgb__colsample_bytree': 0.7019657569426287}. Best is trial 47 with value: 0.9422950819672131.\n",
      "[I 2023-09-04 11:10:34,110] Trial 49 finished with value: 0.9415201192250372 and parameters: {'xgb__n_estimators': 174, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.19062200678529134, 'xgb__subsample': 0.9915769741948391, 'xgb__colsample_bytree': 0.7467812414204656}. Best is trial 47 with value: 0.9422950819672131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo XGBoost: 0.94\n",
      "ROC-AUC do modelo XGBoost: 0.98\n",
      "Matriz de Confusão XGBoost:\n",
      "[[ 8935   484]\n",
      " [  754 11395]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50) \n",
    "best_params_xgb = study_xgb.best_params\n",
    "\n",
    "pipeline_xgb.set_params(**best_params_xgb)\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = pipeline_xgb.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f'Acurácia do modelo XGBoost: {accuracy_xgb:.2f}')\n",
    "\n",
    "y_prob_xgb = pipeline_xgb.predict_proba(X_test)[:, 1]\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
    "print(f'ROC-AUC do modelo XGBoost: {roc_auc_xgb:.2f}')\n",
    "\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "print('Matriz de Confusão XGBoost:')\n",
    "print(conf_matrix_xgb)\n",
    "\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_xgb))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC XGBoost')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "pipeline_lgbm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('lgbm', lgb.LGBMClassifier())]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'lgbm__n_estimators': trial.suggest_int('lgbm__n_estimators', 50, 200),\n",
    "        'lgbm__max_depth': trial.suggest_int('lgbm__max_depth', 3, 10),\n",
    "        'lgbm__learning_rate': trial.suggest_float('lgbm__learning_rate', 0.01, 0.3),\n",
    "        'lgbm__subsample': trial.suggest_float('lgbm__subsample', 0.6, 1.0),\n",
    "        'lgbm__colsample_bytree': trial.suggest_float('lgbm__colsample_bytree', 0.6, 1.0),\n",
    "    }\n",
    "    pipeline_lgbm.set_params(**params)\n",
    "    cv_scores = cross_val_score(pipeline_lgbm, X_train, y_train, cv=5)\n",
    "    return cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:10:52,683] A new study created in memory with name: no-name-8e18a52a-3e35-4db8-9310-e18ca7400dd0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:10:54,741] Trial 0 finished with value: 0.9409239940387482 and parameters: {'lgbm__n_estimators': 64, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.24057059810859663, 'lgbm__subsample': 0.7155137033689399, 'lgbm__colsample_bytree': 0.7082295822105987}. Best is trial 0 with value: 0.9409239940387482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:10:57,274] Trial 1 finished with value: 0.9412419274714356 and parameters: {'lgbm__n_estimators': 110, 'lgbm__max_depth': 10, 'lgbm__learning_rate': 0.274294986836586, 'lgbm__subsample': 0.7170643422865471, 'lgbm__colsample_bytree': 0.7226954381961932}. Best is trial 1 with value: 0.9412419274714356.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:00,113] Trial 2 finished with value: 0.940943864878291 and parameters: {'lgbm__n_estimators': 156, 'lgbm__max_depth': 4, 'lgbm__learning_rate': 0.18850127178430762, 'lgbm__subsample': 0.776150618900791, 'lgbm__colsample_bytree': 0.7584590702400512}. Best is trial 1 with value: 0.9412419274714356.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:03,745] Trial 3 finished with value: 0.9419970193740685 and parameters: {'lgbm__n_estimators': 166, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.07487680195902044, 'lgbm__subsample': 0.9936294934393506, 'lgbm__colsample_bytree': 0.7743417179970153}. Best is trial 3 with value: 0.9419970193740685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:06,735] Trial 4 finished with value: 0.9386388474913065 and parameters: {'lgbm__n_estimators': 197, 'lgbm__max_depth': 3, 'lgbm__learning_rate': 0.06079071574307859, 'lgbm__subsample': 0.9458505888869896, 'lgbm__colsample_bytree': 0.9474527041603631}. Best is trial 3 with value: 0.9419970193740685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:08,511] Trial 5 finished with value: 0.9408246398410333 and parameters: {'lgbm__n_estimators': 64, 'lgbm__max_depth': 4, 'lgbm__learning_rate': 0.2775095512717549, 'lgbm__subsample': 0.9931268077995018, 'lgbm__colsample_bytree': 0.9665463029719179}. Best is trial 3 with value: 0.9419970193740685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:10,889] Trial 6 finished with value: 0.937645305514158 and parameters: {'lgbm__n_estimators': 116, 'lgbm__max_depth': 3, 'lgbm__learning_rate': 0.08432892700448162, 'lgbm__subsample': 0.6882835194785066, 'lgbm__colsample_bytree': 0.8192002932939224}. Best is trial 3 with value: 0.9419970193740685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:13,634] Trial 7 finished with value: 0.9404669647292598 and parameters: {'lgbm__n_estimators': 111, 'lgbm__max_depth': 6, 'lgbm__learning_rate': 0.05875966719451752, 'lgbm__subsample': 0.6285147881972106, 'lgbm__colsample_bytree': 0.846113901109897}. Best is trial 3 with value: 0.9419970193740685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:17,305] Trial 8 finished with value: 0.9397516145057129 and parameters: {'lgbm__n_estimators': 163, 'lgbm__max_depth': 3, 'lgbm__learning_rate': 0.11713276413338818, 'lgbm__subsample': 0.9973322678046089, 'lgbm__colsample_bytree': 0.8233809436844226}. Best is trial 3 with value: 0.9419970193740685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:20,854] Trial 9 finished with value: 0.9420765027322403 and parameters: {'lgbm__n_estimators': 160, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.18700868152551742, 'lgbm__subsample': 0.8334270891878391, 'lgbm__colsample_bytree': 0.9140804189796696}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:26,861] Trial 10 finished with value: 0.9384798807749627 and parameters: {'lgbm__n_estimators': 198, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.011560747158745444, 'lgbm__subsample': 0.8583451656947464, 'lgbm__colsample_bytree': 0.6080922078288736}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:30,482] Trial 11 finished with value: 0.941599602583209 and parameters: {'lgbm__n_estimators': 156, 'lgbm__max_depth': 10, 'lgbm__learning_rate': 0.15536351022164852, 'lgbm__subsample': 0.8858038374528169, 'lgbm__colsample_bytree': 0.887019561044394}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:34,006] Trial 12 finished with value: 0.9412419274714356 and parameters: {'lgbm__n_estimators': 170, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.19455324647968222, 'lgbm__subsample': 0.8525731320430369, 'lgbm__colsample_bytree': 0.9045759381068765}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:37,125] Trial 13 finished with value: 0.9417188276204669 and parameters: {'lgbm__n_estimators': 133, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.1253456972319677, 'lgbm__subsample': 0.9207346216364188, 'lgbm__colsample_bytree': 0.8894753461208652}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:40,753] Trial 14 finished with value: 0.9414207650273223 and parameters: {'lgbm__n_estimators': 137, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.19175798424895701, 'lgbm__subsample': 0.8097953458493019, 'lgbm__colsample_bytree': 0.9760806634728458}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:44,678] Trial 15 finished with value: 0.9413214108296076 and parameters: {'lgbm__n_estimators': 183, 'lgbm__max_depth': 6, 'lgbm__learning_rate': 0.15069814222823313, 'lgbm__subsample': 0.9325031888179108, 'lgbm__colsample_bytree': 0.7854280995089886}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:48,110] Trial 16 finished with value: 0.9417585692995528 and parameters: {'lgbm__n_estimators': 142, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.2226387383149233, 'lgbm__subsample': 0.8032632166363401, 'lgbm__colsample_bytree': 0.8590504841823728}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:51,266] Trial 17 finished with value: 0.9411823149528068 and parameters: {'lgbm__n_estimators': 89, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.10507419830779409, 'lgbm__subsample': 0.9692263473285643, 'lgbm__colsample_bytree': 0.9937204300712199}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:11:55,253] Trial 18 finished with value: 0.9415002483854943 and parameters: {'lgbm__n_estimators': 181, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.1468880374510348, 'lgbm__subsample': 0.8968535287998689, 'lgbm__colsample_bytree': 0.9216860050119927}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:00,019] Trial 19 finished with value: 0.9398708395429708 and parameters: {'lgbm__n_estimators': 150, 'lgbm__max_depth': 10, 'lgbm__learning_rate': 0.015458846987009625, 'lgbm__subsample': 0.9572468126585871, 'lgbm__colsample_bytree': 0.9232511616690078}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:03,869] Trial 20 finished with value: 0.9409239940387482 and parameters: {'lgbm__n_estimators': 182, 'lgbm__max_depth': 5, 'lgbm__learning_rate': 0.08857226193875262, 'lgbm__subsample': 0.9076826557303713, 'lgbm__colsample_bytree': 0.8585921525392535}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:07,048] Trial 21 finished with value: 0.9412419274714356 and parameters: {'lgbm__n_estimators': 141, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.2265319555091677, 'lgbm__subsample': 0.8107160365125763, 'lgbm__colsample_bytree': 0.8572042065311999}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:10,255] Trial 22 finished with value: 0.9409836065573771 and parameters: {'lgbm__n_estimators': 125, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.22561042202510093, 'lgbm__subsample': 0.8517415031846906, 'lgbm__colsample_bytree': 0.799123397392091}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:14,767] Trial 23 finished with value: 0.9400695479384004 and parameters: {'lgbm__n_estimators': 169, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.29626943820229706, 'lgbm__subsample': 0.7726565135263385, 'lgbm__colsample_bytree': 0.9363800904106478}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:17,951] Trial 24 finished with value: 0.9420566318926975 and parameters: {'lgbm__n_estimators': 143, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.18028204227445022, 'lgbm__subsample': 0.875569176386518, 'lgbm__colsample_bytree': 0.879354076805156}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:20,312] Trial 25 finished with value: 0.9418976651763536 and parameters: {'lgbm__n_estimators': 95, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.17147207381815696, 'lgbm__subsample': 0.8852167227419102, 'lgbm__colsample_bytree': 0.8959689549369362}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:23,490] Trial 26 finished with value: 0.9413412816691504 and parameters: {'lgbm__n_estimators': 150, 'lgbm__max_depth': 6, 'lgbm__learning_rate': 0.13827030037403956, 'lgbm__subsample': 0.9666972089896729, 'lgbm__colsample_bytree': 0.9543732454716073}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:27,394] Trial 27 finished with value: 0.9412021857923497 and parameters: {'lgbm__n_estimators': 173, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.16109601696058623, 'lgbm__subsample': 0.93013209997452, 'lgbm__colsample_bytree': 0.8740969778643027}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:30,813] Trial 28 finished with value: 0.941679085941381 and parameters: {'lgbm__n_estimators': 125, 'lgbm__max_depth': 10, 'lgbm__learning_rate': 0.1308607577767163, 'lgbm__subsample': 0.8679526515149496, 'lgbm__colsample_bytree': 0.9980834230006497}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:34,197] Trial 29 finished with value: 0.9417784401390958 and parameters: {'lgbm__n_estimators': 160, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.1709683453394277, 'lgbm__subsample': 0.8334673140864006, 'lgbm__colsample_bytree': 0.8317351822935308}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:35,825] Trial 30 finished with value: 0.9406259314456035 and parameters: {'lgbm__n_estimators': 57, 'lgbm__max_depth': 5, 'lgbm__learning_rate': 0.2104326682576432, 'lgbm__subsample': 0.9090613394314246, 'lgbm__colsample_bytree': 0.7740472410470489}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:37,912] Trial 31 finished with value: 0.9413810233482364 and parameters: {'lgbm__n_estimators': 76, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.1794620326980769, 'lgbm__subsample': 0.8829855298222936, 'lgbm__colsample_bytree': 0.9053610780566671}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:40,273] Trial 32 finished with value: 0.9414207650273223 and parameters: {'lgbm__n_estimators': 96, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.169102905788716, 'lgbm__subsample': 0.8937347391581592, 'lgbm__colsample_bytree': 0.8855750202479361}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:42,890] Trial 33 finished with value: 0.9408842523596622 and parameters: {'lgbm__n_estimators': 100, 'lgbm__max_depth': 5, 'lgbm__learning_rate': 0.202816245615624, 'lgbm__subsample': 0.9350023431013968, 'lgbm__colsample_bytree': 0.7520567424447707}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:46,626] Trial 34 finished with value: 0.94173869846001 and parameters: {'lgbm__n_estimators': 151, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.17967341458444475, 'lgbm__subsample': 0.8307336173180006, 'lgbm__colsample_bytree': 0.9311797178322831}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:48,859] Trial 35 finished with value: 0.9413015399900647 and parameters: {'lgbm__n_estimators': 84, 'lgbm__max_depth': 6, 'lgbm__learning_rate': 0.25503535782411224, 'lgbm__subsample': 0.8726130313321594, 'lgbm__colsample_bytree': 0.8096222477261124}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:51,838] Trial 36 finished with value: 0.9414207650273223 and parameters: {'lgbm__n_estimators': 131, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.1851208844022654, 'lgbm__subsample': 0.9771501726996016, 'lgbm__colsample_bytree': 0.8324629239511225}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:55,737] Trial 37 finished with value: 0.9415201192250372 and parameters: {'lgbm__n_estimators': 189, 'lgbm__max_depth': 10, 'lgbm__learning_rate': 0.168067611437702, 'lgbm__subsample': 0.943435614944025, 'lgbm__colsample_bytree': 0.9592636168732731}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:12:58,797] Trial 38 finished with value: 0.9411624441132638 and parameters: {'lgbm__n_estimators': 117, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.20755800447132236, 'lgbm__subsample': 0.9973360545744065, 'lgbm__colsample_bytree': 0.9040183459518164}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:01,129] Trial 39 finished with value: 0.9392747143566815 and parameters: {'lgbm__n_estimators': 71, 'lgbm__max_depth': 4, 'lgbm__learning_rate': 0.14207756806820807, 'lgbm__subsample': 0.9489224895719851, 'lgbm__colsample_bytree': 0.8386583692104205}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:05,745] Trial 40 finished with value: 0.9418579234972679 and parameters: {'lgbm__n_estimators': 164, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.1598650361377041, 'lgbm__subsample': 0.9086193947930125, 'lgbm__colsample_bytree': 0.8728140300926158}. Best is trial 9 with value: 0.9420765027322403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:10,703] Trial 41 finished with value: 0.9423348236462991 and parameters: {'lgbm__n_estimators': 166, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.15663222993438017, 'lgbm__subsample': 0.9145035273261696, 'lgbm__colsample_bytree': 0.8726554210611243}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:15,377] Trial 42 finished with value: 0.9417188276204669 and parameters: {'lgbm__n_estimators': 174, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.14613175751790106, 'lgbm__subsample': 0.8938701506858358, 'lgbm__colsample_bytree': 0.8122198399307292}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:19,742] Trial 43 finished with value: 0.9414605067064084 and parameters: {'lgbm__n_estimators': 156, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.1907104672369247, 'lgbm__subsample': 0.9841645269045026, 'lgbm__colsample_bytree': 0.9445794552753783}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:22,956] Trial 44 finished with value: 0.9415399900645802 and parameters: {'lgbm__n_estimators': 146, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.12738718528405402, 'lgbm__subsample': 0.8682234019892237, 'lgbm__colsample_bytree': 0.9067120965542275}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:26,431] Trial 45 finished with value: 0.9417784401390958 and parameters: {'lgbm__n_estimators': 193, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.17896593579522038, 'lgbm__subsample': 0.9194992818712628, 'lgbm__colsample_bytree': 0.8427513167666987}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:30,021] Trial 46 finished with value: 0.9420765027322403 and parameters: {'lgbm__n_estimators': 164, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.11312829302352806, 'lgbm__subsample': 0.9521377083604314, 'lgbm__colsample_bytree': 0.8775221439947443}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:34,545] Trial 47 finished with value: 0.9419771485345254 and parameters: {'lgbm__n_estimators': 165, 'lgbm__max_depth': 10, 'lgbm__learning_rate': 0.11214806810262565, 'lgbm__subsample': 0.9560354009937125, 'lgbm__colsample_bytree': 0.8697191311826347}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:38,872] Trial 48 finished with value: 0.9417784401390958 and parameters: {'lgbm__n_estimators': 177, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.10505108011773194, 'lgbm__subsample': 0.9824122637527268, 'lgbm__colsample_bytree': 0.8492957076376494}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22320, number of negative: 17940\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554396 -> initscore=0.218450\n",
      "[LightGBM] [Info] Start training from score 0.218450\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22321, number of negative: 17939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 40260, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554421 -> initscore=0.218551\n",
      "[LightGBM] [Info] Start training from score 0.218551\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-04 11:13:42,263] Trial 49 finished with value: 0.9416989567809239 and parameters: {'lgbm__n_estimators': 160, 'lgbm__max_depth': 9, 'lgbm__learning_rate': 0.06921736602630005, 'lgbm__subsample': 0.9658703804274891, 'lgbm__colsample_bytree': 0.8797127997029079}. Best is trial 41 with value: 0.9423348236462991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 27901, number of negative: 22424\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 940\n",
      "[LightGBM] [Info] Number of data points in the train set: 50325, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554416 -> initscore=0.218531\n",
      "[LightGBM] [Info] Start training from score 0.218531\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Acurácia do modelo LightGBM: 0.94\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "ROC-AUC do modelo LightGBM: 0.98\n",
      "Matriz de Confusão LightGBM:\n",
      "[[ 8930   489]\n",
      " [  750 11399]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=50) \n",
    "best_params_lgbm = study_lgbm.best_params\n",
    "\n",
    "pipeline_lgbm.set_params(**best_params_lgbm)\n",
    "pipeline_lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbm = pipeline_lgbm.predict(X_test)\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f'Acurácia do modelo LightGBM: {accuracy_lgbm:.2f}')\n",
    "\n",
    "y_prob_lgbm = pipeline_lgbm.predict_proba(X_test)[:, 1]\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_prob_lgbm)\n",
    "print(f'ROC-AUC do modelo LightGBM: {roc_auc_lgbm:.2f}')\n",
    "\n",
    "conf_matrix_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
    "print('Matriz de Confusão LightGBM:')\n",
    "print(conf_matrix_lgbm)\n",
    "\n",
    "fpr_lgbm, tpr_lgbm, _ = roc_curve(y_test, y_prob_lgbm)\n",
    "roc_auc_lgbm = auc(fpr_lgbm, tpr_lgbm)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lgbm, tpr_lgbm, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_lgbm))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC LightGBM')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, f1_score\n",
    "\n",
    "# Calcular acurácia\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_lg = accuracy_score(y_test, y_pred_lg)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "\n",
    "# Calcular AUC\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "roc_auc_lg = roc_auc_score(y_test, y_prob_lg)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_prob_lgbm)\n",
    "\n",
    "# Calcular sensibilidade (recall)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "recall_lg = recall_score(y_test, y_pred_lg)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "recall_lgbm = recall_score(y_test, y_pred_lgbm)\n",
    "\n",
    "# Calcular pontuação F1\n",
    "f1_score_rf = f1_score(y_test, y_pred_rf)\n",
    "f1_score_lg = f1_score(y_test, y_pred_lg)\n",
    "f1_score_xgb = f1_score(y_test, y_pred_xgb)\n",
    "f1_score_lgbm = f1_score(y_test, y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0eba6_row2_col1, #T_0eba6_row2_col4, #T_0eba6_row3_col2, #T_0eba6_row3_col3 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0eba6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0eba6_level0_col0\" class=\"col_heading level0 col0\" >Modelo</th>\n",
       "      <th id=\"T_0eba6_level0_col1\" class=\"col_heading level0 col1\" >Acurácia</th>\n",
       "      <th id=\"T_0eba6_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_0eba6_level0_col3\" class=\"col_heading level0 col3\" >Sensibilidade</th>\n",
       "      <th id=\"T_0eba6_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0eba6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0eba6_row0_col0\" class=\"data row0 col0\" >Random Forest</td>\n",
       "      <td id=\"T_0eba6_row0_col1\" class=\"data row0 col1\" >0.911257</td>\n",
       "      <td id=\"T_0eba6_row0_col2\" class=\"data row0 col2\" >0.949664</td>\n",
       "      <td id=\"T_0eba6_row0_col3\" class=\"data row0 col3\" >0.935715</td>\n",
       "      <td id=\"T_0eba6_row0_col4\" class=\"data row0 col4\" >0.922353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0eba6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0eba6_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_0eba6_row1_col1\" class=\"data row1 col1\" >0.923776</td>\n",
       "      <td id=\"T_0eba6_row1_col2\" class=\"data row1 col2\" >0.958071</td>\n",
       "      <td id=\"T_0eba6_row1_col3\" class=\"data row1 col3\" >0.909211</td>\n",
       "      <td id=\"T_0eba6_row1_col4\" class=\"data row1 col4\" >0.930738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0eba6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0eba6_row2_col0\" class=\"data row2 col0\" >XGBoost</td>\n",
       "      <td id=\"T_0eba6_row2_col1\" class=\"data row2 col1\" >0.942600</td>\n",
       "      <td id=\"T_0eba6_row2_col2\" class=\"data row2 col2\" >0.981308</td>\n",
       "      <td id=\"T_0eba6_row2_col3\" class=\"data row2 col3\" >0.937937</td>\n",
       "      <td id=\"T_0eba6_row2_col4\" class=\"data row2 col4\" >0.948477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0eba6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0eba6_row3_col0\" class=\"data row3 col0\" >LightGBM</td>\n",
       "      <td id=\"T_0eba6_row3_col1\" class=\"data row3 col1\" >0.942554</td>\n",
       "      <td id=\"T_0eba6_row3_col2\" class=\"data row3 col2\" >0.981449</td>\n",
       "      <td id=\"T_0eba6_row3_col3\" class=\"data row3 col3\" >0.938267</td>\n",
       "      <td id=\"T_0eba6_row3_col4\" class=\"data row3 col4\" >0.948454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2229de33350>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = {\n",
    "    'Modelo': ['Random Forest', 'Logistic Regression', 'XGBoost', 'LightGBM'],\n",
    "    'Acurácia': [accuracy_rf, accuracy_lg, accuracy_xgb, accuracy_lgbm],\n",
    "    'AUC': [roc_auc_rf, roc_auc_lg, roc_auc_xgb, roc_auc_lgbm],\n",
    "    'Sensibilidade': [recall_rf, recall_lg, recall_xgb, recall_lgbm],\n",
    "    'F1 Score': [f1_score_rf, f1_score_lg, f1_score_xgb, f1_score_lgbm]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_dict)\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: red' if v else '' for v in is_max]\n",
    "\n",
    "styled_df = df_metrics.style.apply(highlight_max, subset=['Acurácia', 'AUC', 'Sensibilidade', 'F1 Score'], axis=0)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o modelo não possui um grande desbalanceamento das classes, podemos utilizar a **AUC** como uma boa métrica.\n",
    "Avaliando o desempenho nas métricas escolhidas para avaliação, consideramos como melhor modelo o **XGBoost**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
